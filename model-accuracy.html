<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Model accuracy and fit – Guides for Supervised Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./linear-regression.html" rel="next">
<link href="./visualization.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-cd7de1037569933fbb609f06423bd096.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./model-accuracy.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Model accuracy and fit</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Guides for Supervised Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Visualization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./model-accuracy.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Model accuracy and fit</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./beyond-linearity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Beyond linearity</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tree-based.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Tree-based Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./text-mining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Text Mining</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#readings" id="toc-readings" class="nav-link active" data-scroll-target="#readings"><span class="header-section-number">3.1</span> Readings</a></li>
  <li><a href="#how-do-we-estimate-f" id="toc-how-do-we-estimate-f" class="nav-link" data-scroll-target="#how-do-we-estimate-f"><span class="header-section-number">3.2</span> How do we estimate f?</a>
  <ul class="collapse">
  <li><a href="#what-affects-our-ability-to-estimate-f" id="toc-what-affects-our-ability-to-estimate-f" class="nav-link" data-scroll-target="#what-affects-our-ability-to-estimate-f"><span class="header-section-number">3.2.1</span> What affects our ability to estimate f?</a></li>
  </ul></li>
  <li><a href="#model-performance" id="toc-model-performance" class="nav-link" data-scroll-target="#model-performance"><span class="header-section-number">3.3</span> Model performance</a>
  <ul class="collapse">
  <li><a href="#measuring-the-quality-of-fit" id="toc-measuring-the-quality-of-fit" class="nav-link" data-scroll-target="#measuring-the-quality-of-fit"><span class="header-section-number">3.3.1</span> Measuring the Quality of Fit</a></li>
  <li><a href="#bias-variance-trade-off" id="toc-bias-variance-trade-off" class="nav-link" data-scroll-target="#bias-variance-trade-off"><span class="header-section-number">3.3.2</span> Bias-Variance Trade Off</a></li>
  <li><a href="#the-classification-setting" id="toc-the-classification-setting" class="nav-link" data-scroll-target="#the-classification-setting"><span class="header-section-number">3.3.3</span> The classification setting</a></li>
  </ul></li>
  <li><a href="#how-to-estimate-the-generalization-error-emse-reliably-training-and-test-set" id="toc-how-to-estimate-the-generalization-error-emse-reliably-training-and-test-set" class="nav-link" data-scroll-target="#how-to-estimate-the-generalization-error-emse-reliably-training-and-test-set"><span class="header-section-number">3.4</span> How to estimate the generalization error <em>E(MSE)</em> reliably? Training and test set</a>
  <ul class="collapse">
  <li><a href="#how-to-split-the-datasets" id="toc-how-to-split-the-datasets" class="nav-link" data-scroll-target="#how-to-split-the-datasets"><span class="header-section-number">3.4.1</span> How to split the datasets</a></li>
  <li><a href="#considerations-with-the-test-dataest-und-cross-validation" id="toc-considerations-with-the-test-dataest-und-cross-validation" class="nav-link" data-scroll-target="#considerations-with-the-test-dataest-und-cross-validation"><span class="header-section-number">3.4.2</span> considerations with the test dataest und cross validation</a></li>
  <li><a href="#two-alternatives-of-model-selection" id="toc-two-alternatives-of-model-selection" class="nav-link" data-scroll-target="#two-alternatives-of-model-selection"><span class="header-section-number">3.4.3</span> Two alternatives of model selection:</a></li>
  </ul></li>
  <li><a href="#resampling-methods-cross-validation" id="toc-resampling-methods-cross-validation" class="nav-link" data-scroll-target="#resampling-methods-cross-validation"><span class="header-section-number">3.5</span> Resampling Methods: Cross-Validation</a>
  <ul class="collapse">
  <li><a href="#the-validation-set-approach" id="toc-the-validation-set-approach" class="nav-link" data-scroll-target="#the-validation-set-approach"><span class="header-section-number">3.5.1</span> The Validation Set Approach</a></li>
  <li><a href="#leave-one-out-cross-validation-loocv" id="toc-leave-one-out-cross-validation-loocv" class="nav-link" data-scroll-target="#leave-one-out-cross-validation-loocv"><span class="header-section-number">3.5.2</span> Leave-One-Out Cross Validation (LOOCV)</a></li>
  <li><a href="#k-fold-cross-validation" id="toc-k-fold-cross-validation" class="nav-link" data-scroll-target="#k-fold-cross-validation"><span class="header-section-number">3.5.3</span> k-Fold Cross-Validation</a></li>
  </ul></li>
  <li><a href="#in-r" id="toc-in-r" class="nav-link" data-scroll-target="#in-r"><span class="header-section-number">3.6</span> in R</a>
  <ul class="collapse">
  <li><a href="#cross-validation-on-classification-problems" id="toc-cross-validation-on-classification-problems" class="nav-link" data-scroll-target="#cross-validation-on-classification-problems"><span class="header-section-number">3.6.1</span> Cross-Validation on Classification Problems</a></li>
  <li><a href="#practice" id="toc-practice" class="nav-link" data-scroll-target="#practice"><span class="header-section-number">3.6.2</span> Practice</a></li>
  <li><a href="#plotting-linear-regression-including-a-prediction-line" id="toc-plotting-linear-regression-including-a-prediction-line" class="nav-link" data-scroll-target="#plotting-linear-regression-including-a-prediction-line"><span class="header-section-number">3.6.3</span> Plotting linear regression including a prediction line</a></li>
  <li><a href="#plotting-linear-regression-with-confindence-or-prediction-intervals" id="toc-plotting-linear-regression-with-confindence-or-prediction-intervals" class="nav-link" data-scroll-target="#plotting-linear-regression-with-confindence-or-prediction-intervals"><span class="header-section-number">3.6.4</span> Plotting linear regression with confindence or prediction intervals</a></li>
  <li><a href="#model-fit-using-the-mean-square-error" id="toc-model-fit-using-the-mean-square-error" class="nav-link" data-scroll-target="#model-fit-using-the-mean-square-error"><span class="header-section-number">3.6.5</span> Model fit using the mean square error</a></li>
  </ul></li>
  <li><a href="#obtaining-train-validation-test-splits" id="toc-obtaining-train-validation-test-splits" class="nav-link" data-scroll-target="#obtaining-train-validation-test-splits"><span class="header-section-number">3.7</span> Obtaining train-validation-test splits</a></li>
  <li><a href="#optional-cross-validation-advanced" id="toc-optional-cross-validation-advanced" class="nav-link" data-scroll-target="#optional-cross-validation-advanced"><span class="header-section-number">3.8</span> Optional: cross-validation (advanced)</a></li>
  <li><a href="#conclusions" id="toc-conclusions" class="nav-link" data-scroll-target="#conclusions"><span class="header-section-number">3.9</span> Conclusions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Model accuracy and fit</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="readings" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="readings"><span class="header-section-number">3.1</span> Readings</h2>
<p><a href="https://static1.squarespace.com/static/5ff2adbe3fe4fe33db902812/t/6062a083acbfe82c7195b27d/1617076404560/ISLR%2BSeventh%2BPrinting.pdf">ISLR</a>:</p>
<ul>
<li>Chapter 2.2: Assessing Model Accuracy</li>
<li>Chapter 5.1: Resampling Methods: Cross-Validation</li>
</ul>
</section>
<section id="how-do-we-estimate-f" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="how-do-we-estimate-f"><span class="header-section-number">3.2</span> How do we estimate f?</h2>
<p>to estimate training data with statistical learning methods: - parametric: make some assumption about the functional form of f, e .g. <span class="math inline">\(Price = \beta_0 + \beta_1 * Tweets\)</span></p>
<p><img src="figures/3.parametric.png" class="img-fluid" width="400"> - for every increase in one tweet, the bitcoin price will increase by 3,543 - methods: linear regression, with quadratic term, with higher-order-polynomials</p>
<ul>
<li>non-parametric: not make an explicit assumptions about the functional form of f, e.g.&nbsp;price of bitcoin is the average of the 3 closest points in our data set</li>
</ul>
<p><img src="figures/3.nonpara.png" class="img-fluid" width="400"></p>
<ul>
<li>methods: non-parametric regression (LOESS, <span class="math inline">\(y_i\)</span> from a “local” regression wihthin a window of its nearest neighbors) or K-NN regression ($y_i predicted from the vale of the closest neighbors)</li>
</ul>
<p>→ so different models to estimate f, which is the best? How to check if the model does a good job? - which predictors is the best? in more complexe models, vertain parameters have to be “tuned”. Which value for these tuned parameters is the best?</p>
<section id="what-affects-our-ability-to-estimate-f" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="what-affects-our-ability-to-estimate-f"><span class="header-section-number">3.2.1</span> What affects our ability to estimate f?</h3>
<ul>
<li>irreducible error</li>
<li>variance of Y</li>
<li>sample size</li>
<li>model &amp; task complexity</li>
</ul>
<p><strong>Example for different</strong> <span class="math inline">\(Var(\epsilon)\)</span>, “noise”</p>
<p>The bigger the “noise” the worse the estimate</p>
<p><img src="figures/3.noise.png" class="img-fluid" width="400"></p>
<ul>
<li>use a more restrictive model</li>
<li>bigger sample size</li>
<li>include other variables</li>
<li>use a method, where some variables are hold fixed</li>
</ul>
<p><strong>Example for sample size</strong></p>
<p>The bigger the sample size, the better the estimate</p>
<p><img src="figures/3.sample.png" class="img-fluid" width="400"></p>
</section>
</section>
<section id="model-performance" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="model-performance"><span class="header-section-number">3.3</span> Model performance</h2>
<p>Example:</p>
<ul>
<li>the left is underfitting the data, the right one is more close to the observations</li>
<li>in practice it is good to know that up to a certain number of tweets, the bitcoin price increase slows down</li>
</ul>
<p><img src="figures/3.model.png" class="img-fluid" width="400"></p>
<p>How can you formalize this, compute the model performance?</p>
<section id="measuring-the-quality-of-fit" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="measuring-the-quality-of-fit"><span class="header-section-number">3.3.1</span> Measuring the Quality of Fit</h3>
<p>Evaluate the performance of a statistical learning method on a given data set in measuring how well its predictions actually match the observed data.</p>
<p>For Regression: mean squared error (MSE)</p>
<p>The Mean squared error (MSE) represents the error of the estimator or predictive model created based on the given set of observations in the sample. Intuitively, the MSE is used to measure the quality of the model based on the predictions made on the entire training dataset vis-a-vis the true label/output value. In other words, it can be used to represent the cost associated with the predictions or the loss incurred in the predictions. And, the squared loss (difference between true &amp; predicted value) is advantageous because they exaggerate the difference between the true value and the predicted value.</p>
<p><span class="math display">\[
MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2,
\]</span> If the MSE is smaller, the predicted responses are very close to the true and vice versa.</p>
<p>With the training MSE, computed out of the training data (<span class="math inline">\(\hat{f}(x_i)\)</span> <span class="math inline">\(\approx\)</span> <span class="math inline">\(y_i\)</span>) we are interested in the accuracy of the predictions with the test set (<span class="math inline">\(\hat{f}(x_0)\)</span> <span class="math inline">\(\approx\)</span> <span class="math inline">\(y_0\)</span>) ) → we want to choose the method that gives us the lowest test MSE, not the lowest training MSE, so we compute the <strong>average squared prediction error</strong> for the test observations:</p>
<p><span class="math display">\[
Ave(y_0-\hat{f}(x_0))^2
\]</span> In some settings, test set is available → sample is split in train and test set What, when no test set available? The learning method is chosen that minimizes the training MSE.</p>
<p><em>Degrees of freedom</em>: A quantity, that summarizes the flexibility of a curve → the more restricted an estimate is, e. g. an estimate computed with regression, the less degrees of freedom the curve has.</p>
<p><strong>Problem of overfitting with taking the training MSE for test MSE</strong></p>
<p>As model flexibility increases, training MSE will decrease, but the test MSE may not. When a given method yields a small training MSE but a large test MSE, we are said to be overfitting the data. This happens because our statistical learning procedure is working too hard to find patterns in the training data, and may be picking up some patterns that are just caused by random chance rather than by true properties of the unknown function f.&nbsp;When we overfit the training data, the test MSE will be very large because the supposed patterns that the method found in the training data simply don’t exist in the test data.</p>
<p>→ traing MSE is smaller than test MSE. Especially when a less flexible model would have yielded a smaller test MSE.</p>
<p><img src="figures/3. model accuracy.png" class="img-fluid" width="490"></p>
<section id="other-measures-of-the-model-accury-besides-the-mse" class="level4" data-number="3.3.1.1">
<h4 data-number="3.3.1.1" class="anchored" data-anchor-id="other-measures-of-the-model-accury-besides-the-mse"><span class="header-section-number">3.3.1.1</span> Other measures of the model accury besides the MSE</h4>
<ul>
<li>Root mean squared error (RMSE): <span class="math display">\[
\sqrt{MSE}
\]</span></li>
</ul>
<p>Mean absolute error (MAE): <span class="math display">\[
MAE= \frac{1}{n} \sum_{i=1}^{n} |y - \hat{y})^2
\]</span></p>
<ul>
<li><p>Median absolute error (mAE): <span class="math display">\[
mAE = median |y - \hat{y})^2
\]</span></p></li>
<li><p>r-Squared: Proportion of variance explained (R2): R2=correlation(y,y^)2</p></li>
</ul>
<p><span class="math display">\[
R^2 = correlation (y, \hat{y})^2
\]</span> <span class="math display">\[
R^2 = \frac{\sum (\hat{y}_i - \overline{y})^2} {\sum y_i - \overline{y})^2}
\]</span> <span class="math display">\[
R^2 = 1- \frac{MSE}{Var(y)}
\]</span> R-Squared is the ratio of the sum of squares regression (SSR) and the sum of squares total (SST). Sum of Squares Regression (SSR) represents the total variation of all the predicted values found on the regression line or plane from the mean value of all the values of response variables. The sum of squares total (SST) represents the total variation of actual values from the mean value of all the values of response variables. R-squared value is used to measure the goodness of fit or best-fit line. The greater the value of R-Squared, the better is the regression model as most of the variation of actual values from the mean value get explained by the regression model. However, we need to take caution while relying on R-squared to assess the performance of the regression model. This is where the adjusted R-squared concept comes into the picture. This would be discussed in one of the later posts. R-Squared is also termed as the coefficient of determination. For the training dataset, the value of R-squared is bounded between 0 and 1, but it can become negative for the test dataset if the SSE is greater than SST. Greater the value of R-squared would also mean a smaller value of MSE. If the value of R-Squared becomes 1 (ideal world scenario), the model fits the data perfectly with a corresponding MSE = 0. As the value of R-squared increases and become close to 1, the value of MSE becomes close to 0.</p>
<p>R-Squared is also termed the standardized version of MSE. R-squared represents the fraction of variance of the actual value of the response variable captured by the regression model rather than the MSE which captures the residual error.</p>
<p><img src="figures/3.R.png" class="img-fluid" width="300"></p>
<p>In this class focus on MSE, with that we can compute our decision and intuition:</p>
<p><img src="figures/3.MSE.png" class="img-fluid" width="400"></p>
<p>Example: Which one is better?</p>
<p><img src="figures/3.MSE2.png" class="img-fluid" width="400"></p>
<p>The left method is overfitting the data and fit to the noise, difficult to interprete.</p>
<p>We want to find a model, that is in the middle, that is “just right”:</p>
<p><img src="figures/3.under,over.png" class="img-fluid" width="400"></p>
<p>So we should not care too much about the MSE, because we already know this observations, we want to understand new data, predict what will happen and generalize.</p>
</section>
</section>
<section id="bias-variance-trade-off" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="bias-variance-trade-off"><span class="header-section-number">3.3.2</span> Bias-Variance Trade Off</h3>
<p>expected test MSE can be decomposed into the sum of three fundamental quantities: variance of <span class="math inline">\(\hat{f}(x_0)\)</span> , squared bias of <span class="math inline">\(\hat{f}(x_0)\)</span> and variance of the error term <span class="math inline">\(\epsilon\)</span>.</p>
<p>The expected test MSE at <span class="math inline">\(x_0\)</span> is:</p>
<p><span class="math display">\[
E(y_o -\hat{f}(x_0))^2 =  Var(\hat{f}(x_0)) + Bias([\hat{f}(x_0))]^2 + Var(\epsilon)
\]</span></p>
<p><span class="math display">\[
E(MSE) = E(\frac{1}{2} \sum_{i=1}^{n} (y - \hat{y})^2) \\
= E(\frac{1}{2} \sum_{i=1}^{n} ( outcome_i - predicted_i)^2) \\
= Bias^2(model) + Variance(model) Variance(\epsilon)
\]</span></p>
<p>The expected test MSE refers to Ave, that we would obtain if repeatedly estimated <span class="math inline">\(f\)</span> using a large number of training sets, and tested each at <span class="math inline">\(x_0\)</span>. Overall expected test MSE can be computed by averaging <span class="math inline">\(E(y_o -\hat{f}(x_0))^2\)</span> over all possible values of <span class="math inline">\(x_0\)</span> in the test set. → for getting a small test MSE, we need a method that simultaneously achieves low variance and low bias (because both is squared it can not be negative). Furthermore expected test MSE can never be lower than <span class="math inline">\(Var(\epsilon)\)</span>, the irreducible error.</p>
<p><em>Variance</em>: refers to the amount by which <span class="math inline">\(\hat{f}\)</span> would change if we estimated it using a different training data set. → more flexible models have higher variance, because it is more volatile. It adapts more to specific to the observations. Variance refers the sensitiviy of our model to small fluctuations in the training dataset. Since the training data are used to fit the statistical learning method, different training data sets will result in a different <span class="math inline">\(\hat{f}\)</span> . High variance often comes from overfitting.</p>
<p><em>Bias</em>: refers to the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much simpler model. In reality not only X influences Y, there are many other variables and linear relationships are unlikely.</p>
<p><strong>Variance</strong><span class="math inline">\((\epsilon)\)</span>: Irreducible error</p>
<p><em>Consequently, the U-shape is result of 2 competing properties</em>: Bias and Variance. If you choose a more flexible method, the Variance will increase but the bias will decrease and vice versa for a more restrictive model. So you need the ideal degree of flexibility, that your test MSE stays small. → that is the bias-variance trade off</p>
<p>MSE is influenced by both bias and variance: Model with high bias: Model that is not able to capture the complexity of the phenomena Model with high variance: Model that easily overfits accidental patterns</p>
<p>in general more flexible models will fit the training data more closely, but they have the problem of overfitting → in the test set you can see the flexible model is printing the noise to and so have at a certain degree higher MSE with increasing flexibility.</p>
<p><img src="figures/3.flexibility.png" class="img-fluid" width="400"></p>
<p><strong>Complexity</strong>: Possible definitions of complexity:</p>
<p>Amount of information in data absorbed into model; Amount of compression performed on data by model; Number of effective parameters, relative to effective degrees of freedom in data. For example: More predictors, more complexity; Higher-order polynomial, more complexity</p>
<p><img src="figures/3.complex.png" class="img-fluid" width="300"></p>
<p><strong>Model complexity vs.&nbsp;interpretability</strong>:</p>
<p><img src="figures/3.flex,int.png" class="img-fluid" width="300"></p>
</section>
<section id="the-classification-setting" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="the-classification-setting"><span class="header-section-number">3.3.3</span> The classification setting</h3>
<p>In this setting, <span class="math inline">\(y_i\)</span> is not metric and the regression logic is not applicable. Most common approach for quantifying the accuracy of estimate <span class="math inline">\(\hat{f}\)</span> is the <em>training error rate</em>, the proportion of mistakes that are made if we apply our estimate <span class="math inline">\(\hat{f}\)</span> to the training observations:</p>
<p><span class="math display">\[
\frac{1}{n}\sum_{i=1}^{n} I(y_i \neq\hat{y_i}).
\]</span></p>
<p><span class="math inline">\(\hat{y_i}\)</span> is class label for the ith observation using <span class="math inline">\(\hat{f}\)</span>. <span class="math inline">\(I(y_i \neq\hat{y_i})\)</span> is indicator variable that equals 1 if <span class="math inline">\(y_i \neq\hat{y_i}\)</span> and 0 if <span class="math inline">\(y_i = \hat{y_i}\)</span>. If <span class="math inline">\(I(y_i \neq\hat{y_i} = 0)\)</span> than the ith observation was classified correctly, otherwise it is misclassified.</p>
<p>We are interested in the <em>test error rate</em>: <span class="math display">\[
AveI(y_0 \neq\hat{y_0})
\]</span> → the smaller the test error, the better the classifier.</p>
<p><strong>The Bayes Classifier</strong></p>
<p>It is possible to show that the test error rate is minimized, on average, by a very simple classifier that assigns each observation to the most likely class, given its predictor values:</p>
<p><span class="math display">\[
Pr(Y = j | X= x_0)
\]</span></p>
<p>conditional probability, is the probability that <span class="math inline">\(Y=j\)</span> given the observed predictor vector <span class="math inline">\(x_0\)</span>.</p>
<p>If there are only two categories (binary) the Bayes classifier predict one class if <span class="math inline">\(Pr(Y = j | X= x_0) &gt; 0.5\)</span> and for class two otherwise.</p>
<p>Example with simulated data, like we have the test set available:</p>
<p><img src="figures/3. bayes.png" class="img-fluid" width="400"></p>
<p>Purple line: here is the probability exactly 50 % → Bayes decision boundary, it is the boundary, from which both observations are assigned to the groups.</p>
<p>The Bayes classifier produces the lowest possible test error rate, called the <em>Bayes error rate</em>, the classifier will always choose the class for which the probability is the largest, so:</p>
<p><span class="math display">\[
1- E( max_j Pr(y=j |X))
\]</span> for all possible X.</p>
<p><strong>K-Nearest Neighbors</strong></p>
<p>In theory we would always like to predict qualitative responses using the Bayes classifier. But for real data, we do not know the conditional distribution of <em>Y</em> given <em>X</em>, and so computing the Bayes classifier is impossible. Therefore, the Bayes classifier serves as an unattainable gold standard against which to compare other methods.</p>
<p>K-Nearest Neighbors (KNN) classifier estimate the conditional distribution of <em>Y</em> given <em>X</em> and then classify a given observation to the class with highest estimated probability.</p>
<p>Given a positive integer K and a test observation <span class="math inline">\(x_0\)</span>, the KNN classifier first identifies the K points in the training data that are closest to <span class="math inline">\(x_0\)</span>, represented by <span class="math inline">\(N_0\)</span>.Then it estimates the conditional probability for class <em>j</em> as the fraction of points in <span class="math inline">\(N_0\)</span>, whose response values equal <em>j</em>:</p>
<p><span class="math display">\[
Pr(Y=j | X= x_0) = \frac{1}{K} \sum_{i \in N_0} I(y_i=j)
\]</span> Finally, test observation <span class="math inline">\(x_0\)</span> to the class with the largest probability like the Bayes classifier.</p>
<p><img src="figures/3. KNN.png" class="img-fluid" width="400"></p>
<p>The choice of K has a drastic effect on the KNN classifier obtained. Figure 2.16 displays two KNN fits to the simulated data from Figure 2.13, using K = 1 and K = 100. When K = 1, the decision boundary is overly flexible and finds patterns in the data that don’t correspond to the Bayes decision boundary. This corresponds to a classifier that has low bias but very high variance. As K grows, the method becomes less flexible and produces a decision boundary that is close to linear. This corresponds to a low-variance but high-bias classifier.</p>
<p><img src="figures/3. KNN2.png" class="img-fluid" width="400"></p>
<p>Just as in the regression setting, there is not a strong relationship between the training error rate and the test error rate. → As in the regression setting, the training error rate consistently declines as the flexibility increases. However, the test error exhibits a characteristic U-shape, declining at first (with a minimum at approximately K = 10) before increasing again when the method becomes excessively flexible and overfits.</p>
</section>
</section>
<section id="how-to-estimate-the-generalization-error-emse-reliably-training-and-test-set" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="how-to-estimate-the-generalization-error-emse-reliably-training-and-test-set"><span class="header-section-number">3.4</span> How to estimate the generalization error <em>E(MSE)</em> reliably? Training and test set</h2>
<p><strong>Why do we want to predict on unseen data?</strong> Conceptually: We often want to understand/predict a general phenomena, not just the observations we already have Pragmatically: It allows to understand if our model is overfitting the data. Idea = you can’t overfit data if you don’t see that data.</p>
<p>Try the function with a new data set. Best practice: Use new data from a later time point. In practice it is really difficult to get data from the future, if you would like predict something, so, we hace to use new observations from the intended prediction situation. Often you only have one dataset, which we split in 2.</p>
<p><strong>Datasets:</strong></p>
<ul>
<li>Training: train the model</li>
<li>observations used to fit <span class="math inline">\(\hat{f}(x)\)</span></li>
<li>Validation: compare between models, tune models, selscz features</li>
<li>new observations from the same source as training data (used several times to select model complexity)</li>
<li>test: assess E(MSE) of the final model</li>
<li>New observations from the intended prediction situation (to evaluate E(MSE) for your final model) –&gt; Only used once in our final model!</li>
</ul>
<p><img src="figures/3.practice.png" class="img-fluid" width="400"></p>
<p><strong>Steps:</strong></p>
<ul>
<li>you will have overfitting only using the training data set</li>
<li>using the training data set to train different models</li>
<li>using the validation set to select the best model</li>
<li>using the test data set to evluate the accuracy of the model (you can not use the validation set, because it is biased. With the validation data set you have selected the best model, so if you would test it with that, too, it is biased)</li>
<li>computed MSE of the test data set to come to the true MSE, the <em>E(MSE)</em> to show, if the model is reliably</li>
</ul>
<p><img src="figures/3.EMSE.png" class="img-fluid" width="400"></p>
<ul>
<li>using the MSE of our models in a new data set, we can see which model is really the best and now we can see that the left one is not the best one, because of overfitting it is not that good fitting to new data → to volatile to the obervations and has been fitted to the noise</li>
</ul>
<p>When comparing the models, you can see, which model is the best: (in real world we do not have the actual distribution of observations, we estimate them)</p>
<p><img src="figures/3.compare.png" class="img-fluid" width="400"> - we can see that the quadratic regression is the best, the KNN regression is overfitting the data.</p>
<p>Example in practice, if we have one dataset:</p>
<ul>
<li>Shuffle the observations</li>
<li>Divide into training (85%) and testing (15%)</li>
<li>Training –&gt; Divide into training (70%) and validation (15%)</li>
<li>Tune models, evaluating models using MSE on the validation set</li>
<li>Select the best model</li>
<li>Use the training + validation set to retrain the final model</li>
<li>Evaluate the model using the test data</li>
</ul>
<p>Problem of bias, because you compare samples, in which the actual worse model fits better with the other samples</p>
<ul>
<li>The validation estimate of the test error can be highly variable</li>
<li>Only a subset of the observations are used to fit the model.</li>
<li>This suggests that the validation set error may tend to overestimate the test error for the model fit on the entire data set.</li>
<li>if performance on validation and performance on test set, start over again</li>
</ul>
<p><img src="figures/3.examplebias.png" class="img-fluid" width="400"></p>
<section id="how-to-split-the-datasets" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="how-to-split-the-datasets"><span class="header-section-number">3.4.1</span> How to split the datasets</h3>
<p>Training: Bulk of observations (~50-80%)</p>
<p>Validation and testing: Smaller subsets (~10-20%) –&gt; Should be representative in order to estimate E(MSE) accurately.</p>
<p>e.g.&nbsp;without cross-validation</p>
<ul>
<li>Training: 50-70%</li>
<li>Validation: 15-25%</li>
<li>Test: 15-25%</li>
</ul>
<p>e.g.&nbsp;with cross-validation</p>
<ul>
<li>Training: 70-80% + 5-10 fold cross-validation to separate into training/validation</li>
<li>Test: 20-30%</li>
</ul>
</section>
<section id="considerations-with-the-test-dataest-und-cross-validation" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="considerations-with-the-test-dataest-und-cross-validation"><span class="header-section-number">3.4.2</span> considerations with the test dataest und cross validation</h3>
<p>The idea is that the <span class="math inline">\(MSE_{test}\)</span> is a good estimate of the <span class="math inline">\(E(MSE)\)</span> (prediction / Bayes error) → This is only true if the test data is similar to the prediction data!</p>
<ul>
<li>sometimes a wrong model is better than a true model, on average better → selecting a simpler model can be better, if you want to show relationships, because world is too complex</li>
<li>these factors together determine what works best:</li>
<li>how close the function form of <span class="math inline">\(\hat{f}(x)\)</span> is to the true <span class="math inline">\(f(x)\)</span>.</li>
<li>the amount of irreducible variance <span class="math inline">\((\omega^2)\)</span></li>
<li>the sample size (n)</li>
<li>the complexity of model (p/df or equivalent)</li>
</ul>
</section>
<section id="two-alternatives-of-model-selection" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="two-alternatives-of-model-selection"><span class="header-section-number">3.4.3</span> Two alternatives of model selection:</h3>
<ul>
<li>Comparing statistical methods (e.g.&nbsp;linear regression vs knn regression)</li>
<li>Comparing models with different predictors included (e.g.&nbsp;linear regression - including predictors [X1, X2] vs [X1, X2, X3] )</li>
<li>Comparing two models with different hyperparameters (e.g.&nbsp;KNN regression using - the closest 3 vs 10 neighbors)</li>
</ul>
</section>
</section>
<section id="resampling-methods-cross-validation" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="resampling-methods-cross-validation"><span class="header-section-number">3.5</span> Resampling Methods: Cross-Validation</h2>
<ul>
<li>Methods for estimating test error rates and thereby choosing the optimal level of flexibility for a given statistical learning method.</li>
<li>involve repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model.</li>
<li>cross-validation can be used to estimate the test error associated with a given statistical learning method in order to evaluate its performance, or to select the appropriate level of flexibility</li>
<li>evaluating model´s perfomance known as <em>model assessment</em>, process of selcting the proper level of flexibility is known as <em>model selection</em>.</li>
<li>basic mechanism: a class of methods that estimate the test error rate by holding out a subset of the training observations from the fitting process, and then applying the statistical learning method to those held out observations</li>
</ul>
<p><strong>The following explanations are first made for regression and afterwards for classification</strong></p>
<section id="the-validation-set-approach" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="the-validation-set-approach"><span class="header-section-number">3.5.1</span> The Validation Set Approach</h3>
<p>Randomly dividing the available set of observations into a model is fit on the training set, and the fitted model is used to predict the responses for the observations in the validation set. → resulting validation set error rate—typically assessed using MSE in the case of a quantitative response—provides an estimate of the test error rate.</p>
<p>This is not only done once, it is done multiple times and tested than.</p>
<p>Problem: The results are not that clear, how much polynominals would produce the lowest MSE. In the Figure each training data produces another degree of polynominal → only thing that can be stated for sure is that a linear fit is not adequate. → very variable → too few observations, overestimate the test error rate</p>
<p><img src="figures/3. validation.png" class="img-fluid" width="400"></p>
</section>
<section id="leave-one-out-cross-validation-loocv" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2" class="anchored" data-anchor-id="leave-one-out-cross-validation-loocv"><span class="header-section-number">3.5.2</span> Leave-One-Out Cross Validation (LOOCV)</h3>
<p>Only a single observation is used for validation. The statistical learning method is fit on the <span class="math inline">\(n - 1\)</span> training observations, and a prediction <span class="math inline">\(\hat{y_1}\)</span> is made for the excluded observation, using its value <span class="math inline">\(x_1\)</span>.<br>
Because <span class="math inline">\((x_1, y_1)\)</span> was not used in the fitting process, <span class="math inline">\(MSE_1 = (y_1-\hat{y_1})^2\)</span> is approximately unbiased estimate for the test error. → because only one observation is highly variable as a check up, same procedure by selecting <span class="math inline">\((x_2, y_2)\)</span> and so on. Tge LOOOCV estimate for the ttest MSE is the average of these <span class="math inline">\(n\)</span> test error estimates:</p>
<p><span class="math display">\[
CV_(n) = \frac{1}{n} \sum_{i=1}^{n} MSE_i
\]</span></p>
<p><em>advantages</em>:</p>
<ul>
<li>far less biased, because only one observation is included in each run → not to overestimate the test error rate</li>
<li>running LOOCV multiple times always yields the same results → no randomness in the splits</li>
</ul>
<p><img src="figures/3. LOOCV.png" class="img-fluid" width="400"></p>
<p>LOOCV has the potential to be expensive to implement, since the model has to be fit <span class="math inline">\(n\)</span> times → shortcut:</p>
<p><span class="math display">\[
CV_(n) = \frac{1}{n} \sum_{i=1}^{n} (\frac{y_i -\hat{y_i}} {1-h_i})^2
\]</span></p>
<section id="high-leverage-points" class="level4" data-number="3.5.2.1">
<h4 data-number="3.5.2.1" class="anchored" data-anchor-id="high-leverage-points"><span class="header-section-number">3.5.2.1</span> high leverage points</h4>
<p><em>Leverage</em> is the influence, that one point has on the regression line, if the point is left out. How huge the leverage of a point is, depends on how far away the observation from other observations is. This is not depend on how much an observation can explain the residual sum of sqares (RSS). It can be, that a point is high in leverage but only explain a little part of RSS and vice versa. Points with a high leverage called high-leverage points. Data points at the edge are more likely to have high leverage than the points in the center.</p>
<p><span class="math inline">\(h_i\)</span> is the leverage (In statistics and in particular in regression analysis, leverage is a measure of how far away the independent variable values of an observation are from those of the other observations. High-leverage points, if any, are outliers with respect to the independent variables):</p>
<p><span class="math display">\[
h_i = \frac{1}{n} + \frac{(x_i - \overline{x})^2} {\sum_{i´=1}^{n} (xi´-\overline{x})^2}
\]</span></p>
<p>Like ordinary MSE, exept the ith residual is devided by <span class="math inline">\(1-h_i\)</span>. Leverage lies between 1/n and 1. Selects the amount that an observation influences its own fit. Hold not in general, in which case the model has to be refit n times.</p>
</section>
</section>
<section id="k-fold-cross-validation" class="level3" data-number="3.5.3">
<h3 data-number="3.5.3" class="anchored" data-anchor-id="k-fold-cross-validation"><span class="header-section-number">3.5.3</span> k-Fold Cross-Validation</h3>
<p>Divided sets of observations into <em>k</em> groups /<em>folds</em> of approximately equal size First fold is validation set, method is fit on the remaing <em>k-1</em> folds <span class="math inline">\(MSE_1\)</span> is then computed on the held-out fold → procedure is repeated -times, each time, with a different group of observations is validation set. k-fold CV estimate:</p>
<p><span class="math display">\[
CV_(k) = \frac{1}{k} \sum_{i=1}^{k} MSE_i
\]</span> Consequently, LOOCV as a special case of the k-fold CV in which <em>k</em> is set to equal <em>n</em>. In practice, k-folds CV often performs using k=5 or k=10. <strong>Advantage</strong>: LOOCV requires fitting the statistical learning method n times. This has the potential to be computationally expensive → then only 5 or 10 times the learning procedure is fitted, more feasible.</p>
<p><img src="figures/3.k-fold.png" class="img-fluid" width="400"></p>
<ul>
<li>only split in training and test data set</li>
<li>‘Cross validation’ often used to replace single dev set approach;</li>
<li>Instead of dividing one time the training dataset (into train/dev), do it many times.</li>
<li>Perform the train/dev split several times, and average the result.</li>
<li>Usually K = 5 or K = 10.</li>
<li>When K = N, ‘leave-one-out’;</li>
</ul>
<p><img src="figures/3.kfold.png" class="img-fluid" width="400"> In all three plots, the two cross-validation estimates are very similar.</p>
<p><strong>Model assessment</strong>: When we perform cross-validation, our goal might be to determine how well a given statistical learning procedure can be expected to perform on independent data; in this case, the actual estimate of the test MSE is of interest.</p>
<p><strong>Model selection</strong>: But at other times we are interested only in the location of the minimum point in the estimated test MSE curve. This is because we might be performing cross-validation on a number of statistical learning methods, or on a single method using different levels of flexibility, in order to identify the method that results in the lowest test error. For this purpose, the location of the minimum point in the estimated test MSE curve is important, but the actual value of the estimated test MSE is not. We find in Figure 5.6 that despite the fact that they sometimes underestimate the true test MSE, all of the CV curves come close to identifying the correct level of flexibility—that is, the flexibility level corresponding to the smallest test MSE.</p>
<section id="bias-variance-trade-off-for-k-fold-cross-validations" class="level4" data-number="3.5.3.1">
<h4 data-number="3.5.3.1" class="anchored" data-anchor-id="bias-variance-trade-off-for-k-fold-cross-validations"><span class="header-section-number">3.5.3.1</span> Bias-Variance Trade-Off for k-Fold Cross-Validations</h4>
<p>k-fold CV has computational advantage to LOOCV and often gives more accurate estimates of test error rate → because of bias-variance trade-off:</p>
<ul>
<li>LOOCV has less bias, because almost all observations are used in the training sets every time. k-fold CV in comparison more biased, because each training set exclude more observations.</li>
<li>LOOCV has higher variance than k-fold CV. In LOOCV averaging the outputs of <em>n</em> fitted models, each of which is trained on an almost identical set of obesrvations → correlation between them is high. Have higher variance, so the test error estimate tends to have higher variance. k-Fold CV with <em>k &lt; n</em> less correlation,overlap bewtween training sets is smaller.<br>
</li>
<li>To summarize, there is a bias-variance trade-off associated with the choice of k in k-fold cross-validation. Typically, given these considerations, one performs k-fold cross-validation using k = 5 or k = 10, as these values have been shown empirically to yield test error rate estimates that suffer neither from excessively high bias nor from very high variance.</li>
</ul>
</section>
</section>
</section>
<section id="in-r" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="in-r"><span class="header-section-number">3.6</span> in R</h2>
<p><strong>Training, Validation, Test:</strong></p>
<pre><code>library(caret)
# define the training partition 
train_index &lt;- createDataPartition(Boston$medv, p = .7, 
                       list = FALSE, 
                       times = 1)

# split the data using the training partition to obtain training data
boston_train &lt;- Boston[train_index,]

# remainder of the split is the validation and test data (still) combined 
boston_val_and_test &lt;- Boston[-train_index,]

# split the remaining 30% of the data in a validation and test set
val_index &lt;- createDataPartition(boston_val_and_test$medv, p = .6, 
                       list = FALSE, 
                       times = 1)

boston_valid &lt;- boston_val_and_test[val_index,]
boston_test  &lt;- boston_val_and_test[-val_index,]


# Outcome of this section is that the data (100%) is split into:
# training (~70%)
# validation (~20%)
# test (~10%)

# Note that creating the partitions using the `y` argument (letting the function know what your dependent variable will be in the analysis), makes sure that when your dependent variable is a factor, the random sampling occurs within each class and should preserve the overall class distribution of the data.



#Then train the model 1 only with the train data
model_1 &lt;- lm(medv ~ lstat, data = boston_train)
summary(model_1)


# Train model 2 only with train data 
model_2 &lt;- lm(medv ~ lstat + age + tax, data = boston_train)
summary(model_2)

#MSE for trained models only show, how well the model perform on the trained data set! For evaluating which model you should choose, validation data set

  # MSE function for evaluation of accuracy 
mse &lt;- function(y_true, y_pred) {
  mean((y_true - y_pred)^2)
}

  # Calculate the MSE for validation
model_1_mse_valid &lt;- mse(y_true = boston_valid$medv, 
                 y_pred = predict(object = model_1, newdata = boston_valid))
model_2_mse_valid &lt;- mse(y_true = boston_valid$medv, 
                 y_pred = predict(model_2, newdata = boston_valid))

# Choose your model (in this case model 2) based on the lower value of validation MSE, because you want the better out-of-sample prediction

# estimate accuracy of your selected model

  #first: train your model again using this time train and validation data
model_2b &lt;- lm(medv ~ lstat + age + tax, data = bind_rows(boston_train, boston_valid))
summary(model_2b)

  #second: predict on the test data:
model_2_mse_test &lt;- mse(y_true = boston_test$medv, 
                y_pred = predict(model_2b, newdata = boston_test))
  #inspect the MSE 
model_2_mse_test

  #compute the R(MSE)
Another quantity that we calculate is the Root Mean Squared Error (RMSE). It is just the square root of the mean square error. That is probably the most easily interpreted statistic, since it has the same units as the quantity plotted on the vertical axis.
Key point: The RMSE is thus the distance, on average, of a data point from the fitted line, measured along a vertical line.
# The estimate for the expected amount of error when predicting the median value of a not previously seen town in Boston when  using this model is:

sqrt(model_2_mse_test)</code></pre>
<p><strong>cross-validation</strong></p>
<pre><code># Just for reference, here is the mse() function once more
mse &lt;- function(y_true, y_pred) mean((y_true - y_pred)^2)

cv_lm &lt;- function(formula, dataset, k) {
  # We can do some error checking before starting the function
  stopifnot(is_formula(formula))     # formula must be a formula
  stopifnot(is.data.frame(dataset))   # dataset must be data frame
  stopifnot(is.integer(as.integer(k))) # k must be convertible to int
  
  # first, add a selection column to the dataset as before
  n_samples  &lt;- nrow(dataset)
  select_vec &lt;- rep(1:k, length.out = n_samples)
  data_split &lt;- dataset %&gt;% mutate(folds = sample(select_vec))
  
  # initialise an output vector of k mse values, which we 
  # will fill by using a _for loop_ going over each fold
  mses &lt;- rep(0, k)
  
  # start the for loop
  for (i in 1:k) {
   # split the data in train and validation set
   data_train &lt;- data_split %&gt;% filter(folds != i)
   data_valid &lt;- data_split %&gt;% filter(folds == i)
   
   # calculate the model on this data
   model_i &lt;- lm(formula = formula, data = data_train)
   
   # Extract the y column name from the formula
   y_column_name &lt;- as.character(formula)[2]
   
   # calculate the mean square error and assign it to mses
   mses[i] &lt;- mse(y_true = data_valid[[y_column_name]],
             y_pred = predict(model_i, newdata = data_valid))
  }
  
  # now we have a vector of k mse values. All we need is to
  # return the mean mse!
  mean(mses)
}

# use the formula to perfom a cross-validation for the model
cv_lm(formula = medv ~ lstat + age + tax, dataset = Boston, k = 9)
  
# the output is the test MSE </code></pre>
<section id="cross-validation-on-classification-problems" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="cross-validation-on-classification-problems"><span class="header-section-number">3.6.1</span> Cross-Validation on Classification Problems</h3>
<p>LOOCV error rate and analogously to that the k-fold CV and validation set error rates:</p>
<p><span class="math display">\[
CV_(n) = \frac{1}{n} \sum_{i_1}^{n} Err_i
\]</span> <span class="math display">\[
Err_i = I(y_i \neq \hat{y_i})
\]</span></p>
<p>logistic regression has not enough flexibility often, therefore an extension is needed → using a polynomial functions of the predictors, e. g. an quadratic logistic regression model with 2 degrees of freedom:</p>
<p><span class="math display">\[
log( \frac{p}{1-p}) = \beta_0 + \beta_1 X_1 + \beta_2 X1^2 + \beta_3 X_2 + \beta_4X_2^2
\]</span></p>
<p><img src="figures/3.degrees.png" class="img-fluid" width="350"></p>
<p>In practice, for real data, the Bayes decision boundary and the test error rates are unknown → cross-validation</p>
<p><img src="figures/3.crossvalidate.png" class="img-fluid" width="350"></p>
<p>→ the 10-fold CS error rate provides a pretty good approximation to the test error rate</p>
<p>→ 10-fold CV error indicates the best value for K, training error rate declies as the method becomes more flexible, so cannot be used to select the optimal value for K.</p>
</section>
<section id="practice" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="practice"><span class="header-section-number">3.6.2</span> Practice</h3>
<p>In this lab, you will learn how to plot a linear regression with confidence and prediction intervals, and various tools to assess model fit: calculating the MSE, making train-test splits, and writing a function for cross validation. You can download the student zip including all needed files for practical 3 <a href="https://surfdrive.surf.nl/files/index.php/s/J58fxg4AkOSKTcK">here</a>.</p>
<p>We will use the <code>Boston</code> dataset, which is in the <code>MASS</code> package that comes with <code>R</code>. In addition, we will make use of the <code>caret</code> package in Part 2 to divide the <code>Boston</code> dataset into a training, test, and validation set.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(scales)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol type="1">
<li><strong>Inspect the Boston dataset using the <code>View()</code> function</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">view</span>(Boston)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>?Boston</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>Boston</code> dataset contains the housing values and other information about Boston suburbs. We will use the dataset to predict housing value (the variable <code>medv</code>, here the outcome/dependent variable) by socio-economic status (the variable <code>lstat</code>, here the predictor / independent variable).</p>
<p><em>medv</em> → Y - median value of owner occupied homes in $1000 steps - metric variable <em>lstat</em> → X - lower status of popultation - in percent, metric variable</p>
<p><em>sample size</em> → 506 rows</p>
<p>Let’s explore socio-economic status and housing value in the dataset using visualization.</p>
<ol start="2" type="1">
<li><strong>Create a scatter plot from the <code>Boston</code> dataset with <code>lstat</code> mapped to the x position and <code>medv</code> mapped to the y position. Store the plot in an object called <code>p_scatter</code>.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>p_scatter <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Boston, <span class="fu">aes</span>(<span class="at">x=</span>lstat, <span class="at">y=</span>medv))<span class="sc">+</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha=</span><span class="fl">0.5</span>)<span class="sc">+</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span> <span class="st">"Housing Values in Boston and the socio-economic status"</span>, <span class="at">x=</span> <span class="st">"percentage of lower status"</span>, <span class="at">y=</span><span class="st">"median value of house"</span>)<span class="sc">+</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()<span class="sc">+</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title=</span><span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">12</span>))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>p_scatter</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="model-accuracy_files/figure-html/sctr-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>p_scatter2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Boston, <span class="fu">aes</span>(<span class="at">x=</span>lstat, <span class="at">y=</span>medv<span class="sc">*</span><span class="dv">1000</span>))<span class="sc">+</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha=</span><span class="fl">0.5</span>)<span class="sc">+</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span> <span class="st">"Housing Values in Boston and the socio-economic status"</span>, <span class="at">x=</span> <span class="st">"percentage of lower status"</span>, <span class="at">y=</span><span class="st">"median value of house"</span>)<span class="sc">+</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels=</span>scales<span class="sc">::</span><span class="fu">label_dollar</span>())<span class="sc">+</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()<span class="sc">+</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title=</span><span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">12</span>))</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>p_scatter2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="model-accuracy_files/figure-html/sctr scales dollar-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="plotting-linear-regression-including-a-prediction-line" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="plotting-linear-regression-including-a-prediction-line"><span class="header-section-number">3.6.3</span> Plotting linear regression including a prediction line</h3>
<p>We’ll start with making and visualizing the linear model. As you know, a linear model is fitted in <code>R</code> using the function <code>lm()</code>, which then returns a <code>lm</code> object. We are going to walk through the construction of a plot with a fit line. During the part done within the lab, we will add prediction and confidence intervals from an <code>lm</code> object to this plot.</p>
<p>First, we will create the linear model. This model will be used to predict outcomes for the current data set, and - further along in this lab - to create new data.</p>
<ol start="3" type="1">
<li><strong>Create a linear model object called <code>lm_ses</code> using the formula <code>medv ~ lstat</code> and the <code>Boston</code> dataset.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>lm_ses <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat, <span class="at">data=</span> Boston)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You have now trained a regression model with <code>medv</code> (housing value) as the outcome/dependent variable and <code>lstat</code> (socio-economic status) as the predictor / independent variable.</p>
<p>Remember that a regression estimates <span class="math inline">\(\beta_0\)</span> (the intercept) and <span class="math inline">\(\beta_1\)</span> (the slope) in the following equation:</p>
<p><span class="math display">\[\boldsymbol{y} = \beta_0 + \beta_1\cdot \boldsymbol{x}_1 + \boldsymbol{\epsilon}\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>p_scatter3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Boston, <span class="fu">aes</span>(<span class="at">x=</span>lstat, <span class="at">y=</span>medv))<span class="sc">+</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha=</span><span class="fl">0.5</span>)<span class="sc">+</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span> <span class="st">"Housing Values in Boston and the socio-economic status"</span>, <span class="at">x=</span> <span class="st">"percentage of lower status"</span>, <span class="at">y=</span><span class="st">"median value of house"</span>)<span class="sc">+</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span>lm, <span class="at">se=</span><span class="cn">TRUE</span>, <span class="at">color=</span><span class="st">"slategray2"</span>)<span class="sc">+</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()<span class="sc">+</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title=</span><span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">12</span>))</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>p_scatter3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="model-accuracy_files/figure-html/scatter lm-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol start="4" type="1">
<li><strong>Use the function <code>coef()</code> to extract the intercept and slope from the <code>lm_ses</code> object. Interpret the slope coefficient.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(lm_ses)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)       lstat 
 34.5538409  -0.9500494 </code></pre>
</div>
</div>
<ul>
<li>There is a negative correlation between the median value of owner occupied houses and the percentage of population with lower status.</li>
<li>The intercept is really high. So with no individuals with lower status lives near by the house, the housing price is 34 000$. If the percentage of people with lower status increases by one, the median value of the owner-occupied homes decreases bei 1000 $.</li>
</ul>
<ol start="5" type="1">
<li><strong>Use <code>summary()</code> to get a summary of the <code>lm_ses</code> object. What do you see? You can use the help file <code>?summary.lm</code>.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_ses)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = medv ~ lstat, data = Boston)

Residuals:
    Min      1Q  Median      3Q     Max 
-15.168  -3.990  -1.318   2.034  24.500 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***
lstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.216 on 504 degrees of freedom
Multiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 
F-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>We can now see the more information about the linear regression.</p>
<ul>
<li>the weighted residuals, the usual residuals rescaled by the square root of the weights specified in the call to lm</li>
<li>degrees of freedom, a 3-vector (p, n-p, p*), the first being the number of non-aliased coefficients, the last being the total number of coefficients.</li>
<li>the coefficients a p x 4 matrix with columns for the estimated coefficient, its standard error, t-statistic and corresponding (two-sided) p-value. Aliased coefficients are omitted.</li>
<li>f statistic (for models including non-intercept terms) a 3-vector with the value of the F-statistic with its numerator and denominator degrees of freedom.</li>
<li>r.squared <span class="math inline">\(R^2\)</span>, the ‘fraction of variance explained by the model’,</li>
</ul>
<p><span class="math display">\[
R^2 = 1 - \frac{ \sum{R_i^2}}{ \sum{(y_i - \hat{y})^2}}
\]</span> where $ is the mean of $y_i}f there is an intercept and zero otherwise.</p>
<p>We now have a model object <code>lm_ses</code> that represents the formula</p>
<p><span class="math display">\[\text{medv}_i = 34.55 - 0.95 * \text{lstat}_i + \epsilon_i\]</span></p>
<p>With this object, we can predict a new <code>medv</code> value by inputting its <code>lstat</code> value. The <code>predict()</code> method enables us to do this for the <code>lstat</code> values in the original dataset.</p>
<ol start="6" type="1">
<li><strong>Save the predicted y values to a variable called <code>y_pred</code></strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_ses, <span class="at">newdata=</span>Boston)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       1        2        3        4        5        6 
29.82260 25.87039 30.72514 31.76070 29.49008 29.60408 </code></pre>
</div>
</div>
<ol start="7" type="1">
<li><strong>Create a scatter plot with <code>y_pred</code> mapped to the x position and the true y value (<code>Boston$medv</code>) mapped to the y value. What do you see? What would this plot look like if the fit were perfect?</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">medv  =</span> Boston<span class="sc">$</span>medv, </span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">y_pred =</span> y_pred)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>pred_scatter <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x=</span>y_pred, <span class="at">y=</span>medv))<span class="sc">+</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha=</span><span class="fl">0.5</span>)<span class="sc">+</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span> <span class="st">"Prediction of median value of house"</span>, <span class="at">x=</span> <span class="st">"prediction"</span>, <span class="at">y=</span><span class="st">"median value of house"</span>)<span class="sc">+</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()<span class="sc">+</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title=</span><span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">12</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>pred_scatter</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="model-accuracy_files/figure-html/predobs-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>If the prediction would be perfect, we had a linear regression line, because the real and the predicted value are not the same, although we have used the same data set.</p>
</section>
<section id="plotting-linear-regression-with-confindence-or-prediction-intervals" class="level3" data-number="3.6.4">
<h3 data-number="3.6.4" class="anchored" data-anchor-id="plotting-linear-regression-with-confindence-or-prediction-intervals"><span class="header-section-number">3.6.4</span> Plotting linear regression with confindence or prediction intervals</h3>
<p>We will continue with the <code>Boston</code> dataset, the created model <code>lm_ses</code> that predicts <code>medv</code> (housing value) by <code>lstat</code> (socio-economic status), and the predicted housing values stored in <code>y_pred</code>.</p>
<p>In addition to predicting housing values for values of <code>lstat</code> observed in the <code>Boston</code> dataset, we also can generate predictions from new values using the <code>newdat</code> argument in the <code>predict()</code> method. For that, we need to prepare a data frame with new values for the original predictors.</p>
<p>One method of number generation, is through using the function <code>seq()</code>, this function from <code>base R</code> generates a sequence of number using a standardized method. Typically length of the requested sequence divided by the range between <code>from</code> to <code>to</code>. For more information call <code>?seq</code>.</p>
<ol start="8" type="1">
<li><strong>Use the <code>seq()</code> function to generate a sequence of 1000 equally spaced values from 0 to 40. Store this vector in a data frame with (<code>data.frame()</code> or <code>tibble()</code>) as its column name <code>lstat</code>. Name the data frame <code>pred_dat</code>.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>pred_dat <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">lstat=</span><span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">40</span>, <span class="at">length.out=</span><span class="dv">1000</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="9" type="1">
<li><ol type="a">
<li><strong>Use the newly created data frame, from Question 8, as the <code>newdata</code> argument to a <code>predict()</code> call for <code>lm_ses</code>. Store it in a variable named <code>y_pred_new</code>.</strong></li>
</ol></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>y_pred_new <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_ses, <span class="at">newdata=</span>pred_dat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we’ll continue with the plotting part by adding a prediction line to the plot we previously constructed.</p>
<ol start="9" type="1">
<li><ol start="2" type="a">
<li><strong>Add the vector <code>y_pred_new</code> to the <code>pred_dat</code> data frame with the name <code>medv</code>.</strong></li>
</ol></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>pred_dat <span class="ot">&lt;-</span> pred_dat <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">medv=</span>y_pred_new)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="10" type="1">
<li><strong>Add a geom_line() to <code>p_scatter</code> from Question 2, with <code>pred_dat</code> as the <code>data</code> argument. What does this line represent?</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>p_scatter <span class="ot">&lt;-</span> <span class="fu">ggplot</span>()<span class="sc">+</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data=</span>Boston, <span class="at">mapping =</span><span class="fu">aes</span>(<span class="at">x=</span>lstat, <span class="at">y=</span>medv, <span class="at">alpha=</span><span class="fl">0.5</span>))<span class="sc">+</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data=</span> pred_dat,<span class="at">mapping=</span> <span class="fu">aes</span>(<span class="at">x=</span>lstat, <span class="at">y=</span>medv))<span class="sc">+</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">title=</span> <span class="st">"Housing Values in Boston and the socio-economic status"</span>, <span class="at">x=</span> <span class="st">"percentage of lower status"</span>, <span class="at">y=</span><span class="st">"median value of house"</span>)<span class="sc">+</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()<span class="sc">+</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title=</span><span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">12</span>))</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>p_scatter</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="model-accuracy_files/figure-html/line-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>This line represents predicted values of medv for the values of lstat.</p>
<ol start="11" type="1">
<li><strong>The <code>interval</code> argument can be used to generate confidence or prediction intervals. Create a new object called <code>y_pred_95</code> using <code>predict()</code> (again with the <code>pred_dat</code> data) with the <code>interval</code> argument set to “confidence”. What is in this object?</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>?predict</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>y_pred_95 <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_ses, <span class="at">newdata =</span>  pred_dat, <span class="at">interval =</span> <span class="st">"confidence"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="12" type="1">
<li><strong>Using the data from Question 11, and the sequence created in Question 8; create a data frame with 4 columns: <code>medv</code>, <code>lstat</code>, <code>lower</code>, and <code>upper</code>.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">cbind</span>(pred_dat, y_pred_95)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span> <span class="fu">select</span>(lstat, medv, lwr, upr)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       lstat     medv      lwr      upr
1 0.00000000 34.55384 33.44846 35.65922
2 0.04004004 34.51580 33.41307 35.61853
3 0.08008008 34.47776 33.37768 35.57784
4 0.12012012 34.43972 33.34229 35.53715
5 0.16016016 34.40168 33.30690 35.49646
6 0.20020020 34.36364 33.27150 35.45578</code></pre>
</div>
</div>
<ol start="13" type="1">
<li><strong>Add a <code>geom_ribbon()</code> to the plot with the data frame you just made. The ribbon geom requires three aesthetics: <code>x</code> (<code>lstat</code>, already mapped), <code>ymin</code> (<code>lower</code>), and <code>ymax</code> (<code>upper</code>). Add the ribbon below the <code>geom_line()</code> and the <code>geom_points()</code> of before to make sure those remain visible. Give it a nice colour and clean up the plot, too!</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>Boston <span class="sc">%&gt;%</span> </span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> lstat, <span class="at">y =</span> medv)) <span class="sc">+</span> </span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lwr, <span class="at">ymax =</span> upr), <span class="at">data =</span> data, <span class="at">fill =</span> <span class="st">"#00008b44"</span>) <span class="sc">+</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">colour =</span> <span class="st">"#883321"</span>) <span class="sc">+</span> </span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> pred_dat, <span class="at">colour =</span> <span class="st">"#00008b"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x   =</span> <span class="st">"Proportion of low SES households"</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">y   =</span> <span class="st">"Median house value"</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">title =</span> <span class="st">"Boston house prices"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="model-accuracy_files/figure-html/plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol start="14" type="1">
<li><strong>Explain in your own words what the ribbon represents.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The ribbon represents the 95% confidence interval of the fit line.</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># The uncertainty in the estimates of the coefficients are taken into</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># account with this ribbon. </span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co"># You can think of it as:</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co"># upon repeated sampling of data from the same population, at least 95% of</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co"># the ribbons will contain the true fit line.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="15" type="1">
<li><strong>Do the same thing, but now with the prediction interval instead of the confidence interval.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pred with pred interval</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>y_pred_95 <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_ses, <span class="at">newdata =</span> pred_dat, <span class="at">interval =</span> <span class="st">"prediction"</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># create the df</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>gg_pred <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">lstat =</span> pred_dat<span class="sc">$</span>lstat,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">medv  =</span> y_pred_95[, <span class="dv">1</span>],</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">l95  =</span> y_pred_95[, <span class="dv">2</span>],</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">u95  =</span> y_pred_95[, <span class="dv">3</span>]</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>Boston <span class="sc">%&gt;%</span> </span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> lstat, <span class="at">y =</span> medv)) <span class="sc">+</span> </span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> l95, <span class="at">ymax =</span> u95), <span class="at">data =</span> gg_pred, <span class="at">fill =</span> <span class="st">"#00008b44"</span>) <span class="sc">+</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">colour =</span> <span class="st">"#883321"</span>) <span class="sc">+</span> </span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> pred_dat, <span class="at">colour =</span> <span class="st">"#00008b"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x    =</span> <span class="st">"Proportion of low SES households"</span>,</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>     <span class="at">y    =</span> <span class="st">"Median house value"</span>,</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>     <span class="at">title =</span> <span class="st">"Boston house prices"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="model-accuracy_files/figure-html/predint-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>While the confidence interval indiciates the uncertainty surrounding the average of y over the sample, the prediction interval quantify the uncertainty for a particular observation. A prediction interval is a type of confidence interval (CI) used with predictions in regression analysis; it is a range of values that predicts the value of a new observation, based on your existing model. Similarly, the prediction interval tells you where a value will fall in the future, given enough samples, a certain percentage of the time. A 95% prediction interval of 100 to 110 hours for the mean life of a battery tells you that future batteries produced will fall into that range 95% of the time. There is a 5% chance that a battery will not fall into this interval. the prediction interval is substantially wider than the confidence interval, reflecting the increased uncertainty</p>
</section>
<section id="model-fit-using-the-mean-square-error" class="level3" data-number="3.6.5">
<h3 data-number="3.6.5" class="anchored" data-anchor-id="model-fit-using-the-mean-square-error"><span class="header-section-number">3.6.5</span> Model fit using the mean square error</h3>
<p>Next, we will write a function to assess the model fit using the mean square error: the square of how much our predictions on average differ from the observed values.</p>
<ol start="16" type="1">
<li><strong>Write a function called <code>mse()</code> that takes in two vectors: true y values and predicted y values, and which outputs the mean square error.</strong></li>
</ol>
<p>Start like so:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> <span class="cf">function</span>(y_true, y_pred) {</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>((y_true <span class="sc">-</span> y_pred)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="https://en.wikipedia.org/w/index.php?title=Mean_squared_error&amp;oldid=857685443">Wikipedia</a> may help for the formula.</p>
<ol start="17" type="1">
<li><strong>Make sure your <code>mse()</code> function works correctly by running the following code.</strong></li>
</ol>
<pre><code>mse(1:10, 10:1)</code></pre>
<p>In the code, we state that our observed values correspond to <span class="math inline">\(1, 2, ..., 9, 10\)</span>, while our predicted values correspond to <span class="math inline">\(10, 9, ..., 2, 1\)</span>. This is graphed below, where the blue dots correspond to the observed values, and the yellow dots correspond to the predicted values. Using your function, you have now calculated the mean squared length of the dashed lines depicted in the graph below. If your function works correctly, the value returned should equal 33.</p>
<p>Visualiation of this:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="model-accuracy_files/figure-html/mseplot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol start="18" type="1">
<li><strong>Calculate the mean square error of the <code>lm_ses</code> model. Use the <code>medv</code> column as <code>y_true</code> and use the <code>predict()</code> method to generate <code>y_pred</code>.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mse</span>(Boston<span class="sc">$</span>medv, <span class="fu">predict</span>(lm_ses))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 38.48297</code></pre>
</div>
</div>
<p>It is not the same values, it is squared, you must use the squared root to get the right unit and not the squared one.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mse</span>(Boston<span class="sc">$</span>medv, <span class="fu">predict</span>(lm_ses)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6.203464</code></pre>
</div>
</div>
<p>You have calculated the mean squared length of the dashed lines in the plot below. As the MSE is computed using the data that was used to fit the model, we actually obtained the training MSE. Below we continue with splitting our data in a training, test and validation set such that we can calculate the out-of sample prediction error during model building using the validation set, and estimate the true out-of-sample MSE using the test set.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="model-accuracy_files/figure-html/mseplot2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Note that you can also easily obtain how much the predictions on average differ from the observed values in the original scale of the outcome variable. To obtain this, you take the root of the mean square error. This is called the Root Mean Square Error, abbreviated as RMSE.</p>
</section>
</section>
<section id="obtaining-train-validation-test-splits" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="obtaining-train-validation-test-splits"><span class="header-section-number">3.7</span> Obtaining train-validation-test splits</h2>
<p>Next, we will use the <code>caret</code> package and the function <code>createDataPartition()</code> to obtain a training, test, and validation set from the <code>Boston</code> dataset. For more information on this package, see the <a href="https://topepo.github.io/caret/index.html">caret website</a>. The training set will be used to fit our model, the validation set will be used to calculate the out-of sample prediction error during model building, and the test set will be used to estimate the true out-of-sample MSE.</p>
<ol start="19" type="1">
<li><strong>Use the code given below to obtain training, test, and validation set from the <code>Boston</code> dataset.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># define the training partition </span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(Boston<span class="sc">$</span>medv, <span class="at">p =</span> .<span class="dv">7</span>, </span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>                       <span class="at">list =</span> <span class="cn">FALSE</span>, </span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">times =</span> <span class="dv">1</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># split the data using the training partition to obtain training data</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>boston_train <span class="ot">&lt;-</span> Boston[train_index,]</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co"># remainder of the split is the validation and test data (still) combined </span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>boston_val_and_test <span class="ot">&lt;-</span> Boston[<span class="sc">-</span>train_index,]</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co"># split the remaining 30% of the data in a validation and test set</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>val_index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(boston_val_and_test<span class="sc">$</span>medv, <span class="at">p =</span> .<span class="dv">6</span>, </span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>                       <span class="at">list =</span> <span class="cn">FALSE</span>, </span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>                       <span class="at">times =</span> <span class="dv">1</span>)</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>boston_valid <span class="ot">&lt;-</span> boston_val_and_test[val_index,]</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>boston_test  <span class="ot">&lt;-</span> boston_val_and_test[<span class="sc">-</span>val_index,]</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Outcome of this section is that the data (100%) is split into:</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a><span class="co"># training (~70%)</span></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a><span class="co"># validation (~20%)</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a><span class="co"># test (~10%)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that creating the partitions using the <code>y</code> argument (letting the function know what your dependent variable will be in the analysis), makes sure that when your dependent variable is a factor, the random sampling occurs within each class and should preserve the overall class distribution of the data.</p>
<p>We will set aside the <code>boston_test</code> dataset for now.</p>
<ol start="20" type="1">
<li><strong>Train a linear regression model called <code>model_1</code> using the training dataset. Use the formula <code>medv ~ lstat</code> like in the first <code>lm()</code> exercise. Use <code>summary()</code> to check that this object is as you expect.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model_1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat, <span class="at">data =</span> boston_train)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = medv ~ lstat, data = boston_train)

Residuals:
    Min      1Q  Median      3Q     Max 
-10.003  -4.129  -1.516   2.057  24.429 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 34.90177    0.67908   51.40   &lt;2e-16 ***
lstat       -0.97911    0.04702  -20.82   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.379 on 354 degrees of freedom
Multiple R-squared:  0.5505,    Adjusted R-squared:  0.5492 
F-statistic: 433.6 on 1 and 354 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<ol start="21" type="1">
<li><strong>Calculate the MSE with this object. Save this value as <code>model_1_mse_train</code>.</strong></li>
</ol>
<p>Sys.setenv(LANG = “en”)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>model_1_mse_train <span class="ot">&lt;-</span> <span class="fu">mse</span>(boston_train<span class="sc">$</span>medv, <span class="fu">predict</span>(model_1, boston_train))</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>model_1_mse_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 40.45739</code></pre>
</div>
</div>
<ol start="22" type="1">
<li><strong>Now calculate the MSE on the validation set and assign it to variable <code>model_1_mse_valid</code>. Hint: use the <code>newdata</code> argument in <code>predict()</code>.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>model_1_mse_valid <span class="ot">&lt;-</span> <span class="fu">mse</span>(boston_valid<span class="sc">$</span>medv, <span class="fu">predict</span>(model_1, boston_valid))</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>model_1_mse_valid</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 35.0634</code></pre>
</div>
</div>
<p>This is the estimated out-of-sample mean squared error.</p>
<ol start="23" type="1">
<li><strong>Create a second model <code>model_2</code> for the train data which includes <code>age</code> and <code>tax</code> as predictors. Calculate the train and validation MSE.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>model_2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat <span class="sc">+</span> age<span class="sc">+</span> tax, <span class="at">data=</span> boston_train)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>model_2_mse_train <span class="ot">&lt;-</span> <span class="fu">mse</span>(<span class="at">y_true=</span> boston_train<span class="sc">$</span>medv, <span class="at">y_pred=</span> <span class="fu">predict</span>(model_2, boston_train))</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>model_2_mse_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 38.08574</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>model_2_mse_valid <span class="ot">&lt;-</span> <span class="fu">mse</span>(<span class="at">y_true =</span>boston_valid<span class="sc">$</span>medv, <span class="at">y_pred=</span><span class="fu">predict</span>(model_2, boston_valid))</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>model_2_mse_valid</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 36.38835</code></pre>
</div>
</div>
<p>If you are interested in out-of-sample prediction, the answer may depend on the random sampling of the rows in the dataset splitting: everyone has a different split. However, it is likely that model_2 has both lower training and validation MSE. In choosing the best model, you should base your answer on the validation MSE. Using the out of sample mean square error, we have made a model decision (which parameters to include, only lstat, or using age and tax in addition to lstat to predict housing value). Now we have selected a final model.</p>
<ol start="24" type="1">
<li><strong>Compare model 1 and model 2 in terms of their training and validation MSE. Which would you choose and why?</strong></li>
</ol>
<p>Model 1 is better, model 2 is overfitting data. Model 1 is better in the validation set and so less biased to the sample split.</p>
<p>I would choose model</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>model_2b <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat <span class="sc">+</span> age <span class="sc">+</span> tax, <span class="at">data =</span> <span class="fu">bind_rows</span>(boston_train, boston_valid))</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_2b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = medv ~ lstat + age + tax, data = bind_rows(boston_train, 
    boston_valid))

Residuals:
    Min      1Q  Median      3Q     Max 
-17.063  -4.010  -1.439   2.146  24.299 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 34.624159   0.861297  40.200  &lt; 2e-16 ***
lstat       -1.037592   0.054288 -19.113  &lt; 2e-16 ***
age          0.053234   0.013247   4.019 6.88e-05 ***
tax         -0.006544   0.002153  -3.040  0.00251 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.162 on 444 degrees of freedom
Multiple R-squared:  0.5756,    Adjusted R-squared:  0.5727 
F-statistic: 200.7 on 3 and 444 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>In choosing the best model, you should base your answer on the validation MSE. Using the out of sample mean square error, we have made a model decision (which parameters to include, only <code>lstat</code>, or using <code>age</code> and <code>tax</code> in addition to <code>lstat</code> to predict housing value). Now we have selected a final model.</p>
<ol start="25" type="1">
<li><strong>For your final model, retrain the model one more time using both the training <em>and</em> the validation set. Then, calculate the test MSE based on the (retrained) final model. What does this number tell you?</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>model_2_mse_test <span class="ot">&lt;-</span> <span class="fu">mse</span>(<span class="at">y_true =</span> boston_test<span class="sc">$</span>medv, </span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">y_pred =</span> <span class="fu">predict</span>(model_2b, <span class="at">newdata =</span> boston_test))</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>model_2_mse_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 32.7281</code></pre>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimate for the expected amount of error when predicting </span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co"># the median value of a not previously seen town in Boston when </span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="co"># using this model is:</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(model_2_mse_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.720848</code></pre>
</div>
</div>
<p>As you will see during the remainder of the course, usually we set apart the test set at the beginning and on the remaining data perform the train-validation split multiple times. Performing the train-validation split multiple times is what we for example do in cross validation (see below). The validation sets are used for making model decisions, such as selecting predictors or tuning model parameters, so building the model. As the validation set is used to base model decisions on, we can not use this set to obtain a true out-of-sample MSE. That’s where the test set comes in, it can be used to obtain the MSE of the final model that we choose when all model decisions have been made. As all model decisions have been made, we can use all data except for the test set to retrain our model one last time using as much data as possible to estimate the parameters for the final model.</p>
</section>
<section id="optional-cross-validation-advanced" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="optional-cross-validation-advanced"><span class="header-section-number">3.8</span> Optional: cross-validation (advanced)</h2>
<p>This is an advanced exercise. Some components we have seen before in this lab, but some things will be completely new. Try to complete it by yourself, but don’t worry if you get stuck. If you don’t know about <code>for loops</code> in <code>R</code>, read up on those before you start the exercise, for example by reading the <a href="https://adav-course-2022.netlify.app/3_mse_cv/basics">Basics: For Loops</a> tab on the course website.</p>
<p>Use help in this order:</p>
<ul>
<li>R help files</li>
<li>Internet search &amp; stack exchange</li>
<li>Your peers</li>
<li>The answer, which shows one solution</li>
</ul>
<p>You may also just read the answer when they have been made available and try to understand what happens in each step.</p>
<ol start="26" type="1">
<li><strong>Create a function that performs k-fold cross-validation for linear models.</strong></li>
</ol>
<p>Inputs:</p>
<ul>
<li><code>formula</code>: a formula just as in the <code>lm()</code> function</li>
<li><code>dataset</code>: a data frame</li>
<li><code>k</code>: the number of folds for cross validation</li>
<li>any other arguments you need necessary</li>
</ul>
<p>Outputs:</p>
<ul>
<li>Mean square error averaged over folds</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Just for reference, here is the mse() function once more</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> <span class="cf">function</span>(y_true, y_pred) <span class="fu">mean</span>((y_true <span class="sc">-</span> y_pred)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>cv_lm <span class="ot">&lt;-</span> <span class="cf">function</span>(formula, dataset, k) {</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># We can do some error checking before starting the function</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stopifnot</span>(<span class="fu">is_formula</span>(formula))     <span class="co"># formula must be a formula</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stopifnot</span>(<span class="fu">is.data.frame</span>(dataset))   <span class="co"># dataset must be data frame</span></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stopifnot</span>(<span class="fu">is.integer</span>(<span class="fu">as.integer</span>(k))) <span class="co"># k must be convertible to int</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># first, add a selection column to the dataset as before</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>  n_samples  <span class="ot">&lt;-</span> <span class="fu">nrow</span>(dataset)</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>  select_vec <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span>k, <span class="at">length.out =</span> n_samples)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>  data_split <span class="ot">&lt;-</span> dataset <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">folds =</span> <span class="fu">sample</span>(select_vec))</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># initialise an output vector of k mse values, which we </span></span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># will fill by using a _for loop_ going over each fold</span></span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>  mses <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, k)</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># start the for loop</span></span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>   <span class="co"># split the data in train and validation set</span></span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a>   data_train <span class="ot">&lt;-</span> data_split <span class="sc">%&gt;%</span> <span class="fu">filter</span>(folds <span class="sc">!=</span> i)</span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a>   data_valid <span class="ot">&lt;-</span> data_split <span class="sc">%&gt;%</span> <span class="fu">filter</span>(folds <span class="sc">==</span> i)</span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb51-25"><a href="#cb51-25" aria-hidden="true" tabindex="-1"></a>   <span class="co"># calculate the model on this data</span></span>
<span id="cb51-26"><a href="#cb51-26" aria-hidden="true" tabindex="-1"></a>   model_i <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> formula, <span class="at">data =</span> data_train)</span>
<span id="cb51-27"><a href="#cb51-27" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb51-28"><a href="#cb51-28" aria-hidden="true" tabindex="-1"></a>   <span class="co"># Extract the y column name from the formula</span></span>
<span id="cb51-29"><a href="#cb51-29" aria-hidden="true" tabindex="-1"></a>   y_column_name <span class="ot">&lt;-</span> <span class="fu">as.character</span>(formula)[<span class="dv">2</span>]</span>
<span id="cb51-30"><a href="#cb51-30" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb51-31"><a href="#cb51-31" aria-hidden="true" tabindex="-1"></a>   <span class="co"># calculate the mean square error and assign it to mses</span></span>
<span id="cb51-32"><a href="#cb51-32" aria-hidden="true" tabindex="-1"></a>   mses[i] <span class="ot">&lt;-</span> <span class="fu">mse</span>(<span class="at">y_true =</span> data_valid[[y_column_name]],</span>
<span id="cb51-33"><a href="#cb51-33" aria-hidden="true" tabindex="-1"></a>             <span class="at">y_pred =</span> <span class="fu">predict</span>(model_i, <span class="at">newdata =</span> data_valid))</span>
<span id="cb51-34"><a href="#cb51-34" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb51-35"><a href="#cb51-35" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb51-36"><a href="#cb51-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># now we have a vector of k mse values. All we need is to</span></span>
<span id="cb51-37"><a href="#cb51-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># return the mean mse!</span></span>
<span id="cb51-38"><a href="#cb51-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(mses)</span>
<span id="cb51-39"><a href="#cb51-39" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="27" type="1">
<li><strong>Use your function to perform 9-fold cross validation with a linear model with as its formula <code>medv ~ lstat + age + tax</code>. Compare it to a model with as formula <code>medv ~ lstat + I(lstat^2) + age + tax</code>.</strong></li>
</ol>
<div class="cell" data-result="hold">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cv_lm</span>(<span class="at">formula =</span> medv <span class="sc">~</span> lstat <span class="sc">+</span> age <span class="sc">+</span> tax, <span class="at">dataset =</span> Boston, <span class="at">k =</span> <span class="dv">9</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 37.78562</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cv_lm</span>(<span class="at">formula =</span> medv <span class="sc">~</span> lstat <span class="sc">+</span> <span class="fu">I</span>(lstat<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> age <span class="sc">+</span> tax, <span class="at">dataset =</span> Boston, <span class="at">k =</span> <span class="dv">9</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 28.20488</code></pre>
</div>
</div>
</section>
<section id="conclusions" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="conclusions"><span class="header-section-number">3.9</span> Conclusions</h2>
<p>We want to learn a model of our data</p>
<ul>
<li>We don’t want to underfit (will have high MSE –&gt; Because of high bias)</li>
<li>We don’t want to overfit (will have high MSE –&gt; Because of high variance) More complex models tend to have higher variance and lower bias</li>
</ul>
<p>We need to choose the correct complexity estimating E(MSE) in the validation dataset</p>
<ul>
<li>Compare between models, tune the hyperparameters of the model or select features</li>
<li>Or even better, cross-validation</li>
</ul>
<p>We can estimate E(MSE) using the test dataset</p>
<ul>
<li>Allows us to understand how the results of our model generalize to unseen data</li>
<li>Done only for the best model (sometimes best k models)</li>
<li>Getting good test data is difficult, unsolved problem Keep in mind that complex models are often less interpretable</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./visualization.html" class="pagination-link" aria-label="Visualization">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Visualization</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./linear-regression.html" class="pagination-link" aria-label="Linear Regression">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Linear Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>