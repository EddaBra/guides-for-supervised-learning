<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Guides for Supervised Learning - 6&nbsp; Beyond linearity</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./tree-based.html" rel="next">
<link href="./classification.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./beyond-linearity.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Beyond linearity</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Guides for Supervised Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Visualization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./model-accuracy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Model accuracy and fit</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./beyond-linearity.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Beyond linearity</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tree-based.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Tree-based Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./text-mining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Text Mining</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#readings" id="toc-readings" class="nav-link active" data-scroll-target="#readings"><span class="header-section-number">6.1</span> Readings</a></li>
  <li><a href="#why-extend-the-linear-model" id="toc-why-extend-the-linear-model" class="nav-link" data-scroll-target="#why-extend-the-linear-model"><span class="header-section-number">6.2</span> Why extend the linear model?</a></li>
  <li><a href="#basic-functions-and-linear-regression" id="toc-basic-functions-and-linear-regression" class="nav-link" data-scroll-target="#basic-functions-and-linear-regression"><span class="header-section-number">6.3</span> Basic functions and linear regression</a></li>
  <li><a href="#polynomial-regression" id="toc-polynomial-regression" class="nav-link" data-scroll-target="#polynomial-regression"><span class="header-section-number">6.4</span> polynomial regression</a>
  <ul class="collapse">
  <li><a href="#interpretations-of-coefficients" id="toc-interpretations-of-coefficients" class="nav-link" data-scroll-target="#interpretations-of-coefficients"><span class="header-section-number">6.4.1</span> Interpretations of coefficients</a></li>
  <li><a href="#use-also-for-logistic-regression" id="toc-use-also-for-logistic-regression" class="nav-link" data-scroll-target="#use-also-for-logistic-regression"><span class="header-section-number">6.4.2</span> use also for logistic regression</a></li>
  </ul></li>
  <li><a href="#advatages-disadvantages" id="toc-advatages-disadvantages" class="nav-link" data-scroll-target="#advatages-disadvantages"><span class="header-section-number">7</span> Advatages &amp; Disadvantages</a></li>
  <li><a href="#stepwise-functions-piecewise-constant-models" id="toc-stepwise-functions-piecewise-constant-models" class="nav-link" data-scroll-target="#stepwise-functions-piecewise-constant-models"><span class="header-section-number">8</span> Stepwise functions = piecewise constant models</a>
  <ul class="collapse">
  <li><a href="#interpretation-of-coefficients" id="toc-interpretation-of-coefficients" class="nav-link" data-scroll-target="#interpretation-of-coefficients"><span class="header-section-number">8.1</span> Interpretation of coefficients</a>
  <ul class="collapse">
  <li><a href="#advatages-disadvantages-1" id="toc-advatages-disadvantages-1" class="nav-link" data-scroll-target="#advatages-disadvantages-1"><span class="header-section-number">8.1.1</span> Advatages &amp; Disadvantages</a></li>
  </ul></li>
  <li><a href="#dicontinuous-piecewise-polynomials" id="toc-dicontinuous-piecewise-polynomials" class="nav-link" data-scroll-target="#dicontinuous-piecewise-polynomials"><span class="header-section-number">8.2</span> Dicontinuous piecewise polynomials</a>
  <ul class="collapse">
  <li><a href="#advatages-disadvantages-2" id="toc-advatages-disadvantages-2" class="nav-link" data-scroll-target="#advatages-disadvantages-2"><span class="header-section-number">8.2.1</span> Advatages &amp; Disadvantages</a></li>
  </ul></li>
  <li><a href="#splines" id="toc-splines" class="nav-link" data-scroll-target="#splines"><span class="header-section-number">8.3</span> Splines</a>
  <ul class="collapse">
  <li><a href="#advatages-disadvantages-3" id="toc-advatages-disadvantages-3" class="nav-link" data-scroll-target="#advatages-disadvantages-3"><span class="header-section-number">8.3.1</span> Advatages &amp; Disadvantages</a></li>
  <li><a href="#constraining-parameters-further-natural-splines" id="toc-constraining-parameters-further-natural-splines" class="nav-link" data-scroll-target="#constraining-parameters-further-natural-splines"><span class="header-section-number">8.3.2</span> Constraining parameters further: natural splines</a></li>
  </ul></li>
  <li><a href="#choosing-k-and-the-placements-of-knots" id="toc-choosing-k-and-the-placements-of-knots" class="nav-link" data-scroll-target="#choosing-k-and-the-placements-of-knots"><span class="header-section-number">8.4</span> Choosing K and the placements of knots</a>
  <ul class="collapse">
  <li><a href="#smoothing-splines" id="toc-smoothing-splines" class="nav-link" data-scroll-target="#smoothing-splines"><span class="header-section-number">8.4.1</span> Smoothing splines</a></li>
  </ul></li>
  <li><a href="#local-regression" id="toc-local-regression" class="nav-link" data-scroll-target="#local-regression"><span class="header-section-number">8.5</span> Local regression</a></li>
  <li><a href="#generalized-additive-models-gam" id="toc-generalized-additive-models-gam" class="nav-link" data-scroll-target="#generalized-additive-models-gam"><span class="header-section-number">8.6</span> Generalized additive models (GAM)</a></li>
  <li><a href="#in-r" id="toc-in-r" class="nav-link" data-scroll-target="#in-r"><span class="header-section-number">8.7</span> in R</a>
  <ul class="collapse">
  <li><a href="#polynomial-regression-1" id="toc-polynomial-regression-1" class="nav-link" data-scroll-target="#polynomial-regression-1"><span class="header-section-number">8.7.1</span> Polynomial regression</a></li>
  <li><a href="#piecewise-constant-step-function" id="toc-piecewise-constant-step-function" class="nav-link" data-scroll-target="#piecewise-constant-step-function"><span class="header-section-number">8.7.2</span> Piecewise constant (Step function)</a></li>
  <li><a href="#splines-1" id="toc-splines-1" class="nav-link" data-scroll-target="#splines-1"><span class="header-section-number">8.7.3</span> Splines</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Beyond linearity</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="readings" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="readings"><span class="header-section-number">6.1</span> Readings</h2>
<p><a href="https://static1.squarespace.com/static/5ff2adbe3fe4fe33db902812/t/6062a083acbfe82c7195b27d/1617076404560/ISLR%2BSeventh%2BPrinting.pdf">ISLR</a></p>
<p>Chapter 7: Beyond linearity</p>
</section>
<section id="why-extend-the-linear-model" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="why-extend-the-linear-model"><span class="header-section-number">6.2</span> Why extend the linear model?</h2>
<ul>
<li>More flexibility, while still being able to interpret the outcomes of the model.</li>
<li>In (even) more flexible models (such as Random Forests, will be discussed in two weeks) interpretability is limited</li>
</ul>
<p><img src="figures/6.types.png" class="img-fluid" width="400"></p>
<p><img src="figures/6.types2.png" class="img-fluid" width="490"></p>
<ul>
<li>easy to code, only one line!</li>
<li><em>Polynomial regression</em> extends the linear model by adding extra predictors, obtained by raising each of the original predictors to a power. For example, a cubic regression uses three variables, X, X2, and X3, as predictors. This approach provides a simple way to provide a nonlinear fit to data.</li>
<li><em>Step functions</em> cut the range of a variable into K distinct regions in order to produce a qualitative variable. This has the effect of fitting a piecewise constant function.</li>
<li><em>Regression</em> splines are more flexible than polynomials and step functions, and in fact are an extension of the two. They involve dividing the range of X into K distinct regions. Within each region, a polynomial function is fit to the data. However, these polynomials are constrained so that they join smoothly at the region boundaries, or knots. Provided that the interval is divided into enough regions, this can produce an extremely flexible fit. Smoothing splines are similar to regression splines, but arise in a slightly different situation. Smoothing splines result from minimizing a residual sum of squares criterion subject to a smoothness penalty.</li>
<li><em>Local regression (LOESS)</em> is similar to splines, but differs in an important way. The regions are allowed to overlap, and indeed they do so in a very smooth way.</li>
<li><em>Generalized additive models</em> allow us to extend the methods above to deal with multiple predictors.</li>
</ul>
</section>
<section id="basic-functions-and-linear-regression" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="basic-functions-and-linear-regression"><span class="header-section-number">6.3</span> Basic functions and linear regression</h2>
<p>General idea:</p>
<ul>
<li>We have a non-linear relationship between <em>X</em> and <em>Y</em>.</li>
<li>We replace <em>X</em> by <span class="math inline">\(b_1(x), b_2(x)\)</span> etc., choosing the <span class="math inline">\(b_j()\)</span> so the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(b_j(x)\)</span> is linear</li>
<li>we fit our linear regression <span class="math display">\[
f(x) = \beta_0 b_1(x) + \beta_1 b_2(x) + \beta2 b_j(x)
\]</span></li>
<li>we can get the <span class="math inline">\(\beta\)</span> s estimate standard errors etc.</li>
</ul>
<p>The basis function <span class="math inline">\(b()\)</span> are fixed and known. Linear regression is a special case where <span class="math inline">\(b_0(x) = 1\)</span> and <span class="math inline">\(b_1(x) = x\)</span> because the intercept <span class="math inline">\(\beta_0\)</span> does not interact with <span class="math inline">\(x\)</span> and we only have one <span class="math inline">\(x\)</span> - Linear regression:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1x + \epsilon
\]</span></p>
</section>
<section id="polynomial-regression" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="polynomial-regression"><span class="header-section-number">6.4</span> polynomial regression</h2>
<p><span class="math display">\[
y = \beta_0 + \beta_1x  +  \beta_2x^2 + \dots + \beta_d^d  + \epsilon
\]</span></p>
<p><span class="math inline">\(b_0(x) =1\)</span> is the intercept</p>
<p><span class="math inline">\(d\)</span> stands for the degree of freedom (quantity that summarizes the flexibility of a curve) - for polynomial regression usually not greater than 3 or 4, because then it would be too flexible or use cross-validation to choose . - for each extra degree in the polynomials, the linear prediction line is ‘allowed’ to make one extra bend.</p>
<p><img src="figures/6.poly.png" class="img-fluid" width="490"></p>
<section id="interpretations-of-coefficients" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="interpretations-of-coefficients"><span class="header-section-number">6.4.1</span> Interpretations of coefficients</h3>
<ul>
<li>Typically, we are not so interested in the values of the regression coefficients <span class="math inline">\(\beta_0\)</span>, but more in: The predicted outcome for each value of <span class="math inline">\(x_i\)</span> (i.e., the fitted function values) How much increases when we increase <span class="math inline">\(x\)</span> (i.e., the marginal effect)</li>
</ul>
<p>Therefore, <strong>marginal effect plot</strong></p>
<ul>
<li>The plot shows, how the rate of the curve changes with increasing x.</li>
<li>in linear models, the marginal effect stays the same, because the gradient is always the same</li>
<li>with each step in <code>fixed_acidity</code> / in <span class="math inline">\(x\)</span>, the outcome will decrease by -0-06-</li>
</ul>
<p><img src="figures/6.melin.png" class="img-fluid" width="200"></p>
<ul>
<li>in quadric regression:</li>
<li>With every extra point on fixed acidity, the pH is predicted to go down with 0.18 points.</li>
<li>However, as fixed acidity increases, the negative effect levels off with 0.01 points per point on fixed <span class="math inline">\(acidity^2\)</span></li>
<li>With every extra point on fixed acidity, the decrease on pH depends on the level of fixed acidity</li>
<li>The marginal effect is the derivative (Ableitung) of f(x) (i.e.&nbsp;the slope of the curve at each point)</li>
</ul>
<p><img src="figures/6.mequa.png" class="img-fluid" width="200"></p>
<ul>
<li>cubic regression:</li>
<li>With a fixed acidity of 0, the predicted pH equals 5.50</li>
<li>With every extra point on fixed acidity, the pH is predicted to go down with 0.57 points</li>
<li>This negative effect levels off with 0.05 points per point on fixed <span class="math inline">\(acidity^2\)</span></li>
<li>As acidity increases, the ‘levelling off’ effect is negated with 0.001 points per point on fixed <span class="math inline">\(acidity^3\)</span></li>
</ul>
<p><img src="figures/6.mecu.png" class="img-fluid" width="200"></p>
<p><strong>Example: how to interpret?</strong></p>
<p><img src="figures/6.coe.png" class="img-fluid" width="100"></p>
<p><img src="figures/6.predict.png" class="img-fluid" width="300"></p>
<ul>
<li>at 10 the second estimated parameter works, so for an increase in fixed_acidity in one, the estimate is 0.049</li>
<li>for 0.01 you have then 0.0049</li>
</ul>
</section>
<section id="use-also-for-logistic-regression" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="use-also-for-logistic-regression"><span class="header-section-number">6.4.2</span> use also for logistic regression</h3>
<p><span class="math display">\[
Pr(y_i = 1| X) = \frac{e_{\beta_0 + \beta_1x_i + \beta_2x_i^2 + \dots + \beta_dx_i^d}} { 1+e_{\beta_0 + \beta_1x_i + \beta_2x_i^2 + \dots + \beta_dx_i^d}}
\]</span></p>
<p><img src="figures/6.log.png" class="img-fluid" width="490"></p>
<p><strong>in R</strong></p>
<p><code>poly()</code> function, to specify your polynomial inside a formula for a linear (or logistic) regression as such:</p>
<p>Here three degree polynomial</p>
<p><code>mod &lt;- lm(pH ~ poly(fixed_acidity, degree = 3), data = winequality_red)</code></p>
</section>
</section>
<section id="advatages-disadvantages" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Advatages &amp; Disadvantages</h1>
<p>Advantages</p>
<ul>
<li>Simple model, easy to understand</li>
<li>some relationships are actually polynomial</li>
</ul>
<p>Why are not polynomials not good enough?</p>
<ul>
<li>Polynomials have notorious ‘tail’ behavior → dangerous to extrapolate predictions outside what is observed in the data! points at the end of the curves are really bad to extrapolate! Curves go to much in one direction!</li>
<li>They are non-local: the behavior of a polynomial at a point <span class="math inline">\(x_i\)</span> can depend strongly on points far <span class="math inline">\(x_i\)</span>from .</li>
</ul>
<p>Better approach: Splines But before that you have to understand stepwise functions and piecewise polynomials</p>
</section>
<section id="stepwise-functions-piecewise-constant-models" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Stepwise functions = piecewise constant models</h1>
<p>Better approach than polynomials, because do not distort the ends. Is problematic, if you want to predict values outside the test data range!</p>
<p>Using polynomial functions of the features as predictors in a linear model imposes a global structure on the non-linear function of X. We can instead use step functions in order to avoid imposing such a global structure. Here step we break the range of X into bins, and fit a different constant in each bin. This amounts to converting a continuous variable into an ordered categorical variable.</p>
<p>Instead of using polynomials, we can also cut the variable into distinct regions (bins) → defining this regions by set a certain threshold!</p>
<p>We fit separate values for different regions of <span class="math inline">\(X\)</span>, for example:</p>
<p><img src="figures/6.step.png" class="img-fluid" width="100"></p>
<ul>
<li>sorts the observations in one of this exclusive categories -&gt; each observations in category bigger than or less than the threshold</li>
</ul>
<p>Second option, we use a intercept, that is our baseline and is a dummy variable</p>
<p><img src="figures/6.step2.png" class="img-fluid" width="100"></p>
<p><img src="figures/6.step3.png" class="img-fluid" width="200"></p>
<ul>
<li>set a dummy variable, an indicator, with range of 0 or 1 when I is true, and zero, if not! In this case, lines are continous, not broken into two</li>
</ul>
<section id="interpretation-of-coefficients" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="interpretation-of-coefficients"><span class="header-section-number">8.1</span> Interpretation of coefficients</h2>
<p>For example:</p>
<p><code>st2_logb &lt;- lm(pH ~ I(fixed_acidity &gt; 6 &amp; fixed_acidity &lt; 8) + I(fixed_acidity &gt;= 8), data = winequality</code></p>
<p><img src="figures/6.step4.png" class="img-fluid" width="100"></p>
<p><img src="figures/6.step5.png" class="img-fluid" width="100"></p>
<p>6 and 8 are chosen as thresholds (In real practice, you do not choose 6 and 8 by cut the curve by certain steps, like every 3 points in X I compute another estimate)</p>
<p>for example, if I want to predict for X=12, I use this estimate! Because the threshold here is &gt;= 8. If I want to predict 7, I use the 0.2 estimate.</p>
<p>Interpretation of the coefficients: - Intercept: Value of before the first knot - I(fixed_acidity &gt; 6 &amp; fixed_acidity &lt; 8): Value of between the first and second knots (in relationship to the intercept) - I(fixed_acidity &gt;= 8): Value of after the second knot (in relationship to the intercept)</p>
<p><img src="figures/6.step5.png" class="img-fluid" width="400"></p>
<ul>
<li>in this model accumulated!</li>
<li>if you have model like this, we have estimates that accumulate! So for X=12 we have to use -021 and -0.15</li>
<li>Each function gets activated at a different break, adding to the previous.</li>
</ul>
<section id="advatages-disadvantages-1" class="level3" data-number="8.1.1">
<h3 data-number="8.1.1" class="anchored" data-anchor-id="advatages-disadvantages-1"><span class="header-section-number">8.1.1</span> Advatages &amp; Disadvantages</h3>
<p>Advantages: - Simple - Popular in epedemiology and biostatistics - Useful when there are natural cutpoints that are of interest (e.g., students under and over 18) - Interpretation is easy: the coefficients show the predicted value - They are local: in step functions, regression coefficients only influence outcomes in a specific region, while with polynomials the regression coefficients influcence the predicted outcome for all ranges of</p>
<p>Disadvantages: - They are not continuous</p>
<p><strong>in R</strong></p>
<p>Number of breaks (or and where to cut is decided by the user.</p>
<p>In R: <code>cut(predictor, c(breaks))</code></p>
<p>When the location of the breaks is not specified, the breaks are spaced evenly</p>
<pre><code>#use cut
pw2_mod &lt;- lm(pH ~ cut(fixed_acidity, breaks = c(0,6,8,14)), data = winequality_red) 

#use I
new_mod &lt;- lm(pH ~ I(fixed_acidity &gt; 6) + I(fixed_acidity &gt; 8), data = winequality_red)</code></pre>
</section>
</section>
<section id="dicontinuous-piecewise-polynomials" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="dicontinuous-piecewise-polynomials"><span class="header-section-number">8.2</span> Dicontinuous piecewise polynomials</h2>
<ul>
<li>Combination of polynomial regression and step function:</li>
<li>We fit separate low-degree polynomials over different regions of X, for example:</li>
</ul>
<p><img src="figures/6.piece.png" class="img-fluid" width="100"></p>
<ul>
<li>parameters <span class="math inline">\((d+1)(K+1))\)</span> where K= numbers of knots / breaks k</li>
<li>if you have one break, you have two number of polynomials</li>
<li>using more knots means more flexible piecewise polynomial functions, because we subset the data in <span class="math inline">\(x_i &lt; \xi\)</span> and in <span class="math inline">\(x_i &gt;= \xi\)</span></li>
<li>the polinomials are indicated by the second number, so <span class="math inline">\(\beta_01\)</span> is the intercept of the first regression line, <span class="math inline">\(\beta_02\)</span> is the intercept for the second regression line. So we have two cubic regression lines with each 3 degrees of freedom that are merged into one.</li>
<li>If maximum degree is 1 = we fit linear functions</li>
<li>If maximum degree is 3 = cubic polynomials</li>
</ul>
<p><img src="figures/6.piece2.png" class="img-fluid" width="250"></p>
<section id="advatages-disadvantages-2" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="advatages-disadvantages-2"><span class="header-section-number">8.2.1</span> Advatages &amp; Disadvantages</h3>
<p>Advantage: more flexible than step functions</p>
<p>Disadvantage: still discontinous</p>
<p>Solution: Splines</p>
</section>
</section>
<section id="splines" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="splines"><span class="header-section-number">8.3</span> Splines</h2>
<p>We add constraints to the former piecewise polynomials: 1. Splines have a maximum amount of continuity: The <span class="math inline">\(d- 1\)</span> derivatives are constrained to be continuous at the knot as well. For example, if we use a cubic function <span class="math inline">\(( d= 3)\)</span>, we force the <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span> derivative to be continuous as well → very important! 2. This means that cubic splines are not only continuous, but also have the same slope (1 derivative) and curvature (2 derivative)</p>
<p>The following image shows, why the spline is the best solution:</p>
<p><img src="figures/6.splines.png" class="img-fluid" width="400"></p>
<ul>
<li>piecewise cubic is not continuous, we have two intercepts</li>
<li>removing this intercept, in fact we have a continuous curve, but it looks not very natural</li>
<li>in rhe cubic spline, we have added the two constraints: at the threshold ‘age=50’ both derivates are continuous and the curve is also very smooth!</li>
<li>in doing this, we restrict the number of degrees of freedom: Each constraint that we impose on the piecewise cubic polynomials effectively frees up one degree of freedom, by reducing the complexity of the resulting piecewise polynomial fit. So in the top left plot, we are using eight degrees of freedom, but in the bottom left plot we imposed three constraints (continuity, continuity of the first derivative, and continuity of the second derivative)</li>
<li>In general, a cubic spline with K knots usesa total of 4 + K degrees of freedom.</li>
<li>in the right lower panel we have a linear spline, which is also continuous at ‘age=50’</li>
<li>The general definition of a degree-d spline is that it is a piecewise degree-d polynomial, with continuity in derivatives up to degree d − 1 at each knot. Therefore, a linear spline is obtained by fitting a line in each region of the predictor space defined by the knots, requiring continuity at each knot.</li>
</ul>
<p>Fore splines we use a <strong>truncated basis function</strong>.</p>
<p><img src="figures/6.splines2.png" class="img-fluid" width="100"></p>
<ul>
<li>we estimate two different regression lines, seperated by the threshold <span class="math inline">\(\xi\)</span></li>
<li>first linear regression use all observations, then add a second regression to it (like in the stepwise) at a certain threshold <span class="math inline">\(\xi\)</span>. Problem now are the breaks!</li>
<li>therefore, we restrict the number of <span class="math inline">\(d\)</span> in performing a least squares regression with an intercept and <span class="math inline">\(d+K\)</span> predictors to have the form of <span class="math inline">\(X, X^2, X^3\)</span>, <span class="math inline">\(h(X,\xi_1),h(X,\xi_2), \dots ..., h(X,\xi_3)\)</span>, where <span class="math inline">\(\xi\)</span> are the knots</li>
<li>so we have a formula</li>
<li>for a cubic spline we have then 4 degrees of freedom, because the intercept is also one: <span class="math inline">\(b_0(x) = Intercept 1, b_1(x)= x, b_2(x)= x^2, b_3(x)=x^3\)</span> where it is <span class="math inline">\(b_{d+k}(x) = (x-\xi_k)_+^d for k=1, \dots, K\)</span></li>
</ul>
<p><span class="math display">\[
f(x) = \beta_0 + \beta_1x_i + \beta_2(x_i-\xi_k)
\]</span> Very common to use the cubic splines, because 1. &amp; 2. derivate are smooth, continuous, same slope, same curvature (Krümmung, Wölbung) and going past cubic dies not get much scmoother-looking curves</p>
<p><strong>What happens at the treshold to make the spline continuous and smooth?</strong></p>
<p><span class="math display">\[
\begin{align*}
f(x) &amp; = \beta_0 + \beta_1\xi \\
Before  &amp;  \xi  (e.g. at \xi - \delta) \\
f(x)  &amp; = \beta_0 + \beta_1\xi - \beta_1\delta \\
After &amp;  \xi  (e.g. at \xi + \delta) \\
f(x)  &amp; = \beta_0 + \beta_1\xi - (\beta_1 + \beta_2)\delta \\
\end{align*}
\]</span></p>
<p><strong>Truncaded power basis function</strong></p>
<p><img src="figures/6.splines3.png" class="img-fluid" width="100"></p>
<section id="advatages-disadvantages-3" class="level3" data-number="8.3.1">
<h3 data-number="8.3.1" class="anchored" data-anchor-id="advatages-disadvantages-3"><span class="header-section-number">8.3.1</span> Advatages &amp; Disadvantages</h3>
<p>Pro: Continuous and smooth!</p>
<p>Con: Prediction outside the range of the data can be wild</p>
<p><strong>in R</strong></p>
<pre><code>library(splines)
bs3_l_mod &lt;- lm(pH ~ bs(fixed_acidity, knots = c(6,8)), data = winequality_red)
bs3_l_log &lt;- glm(Survived ~ bs(Age, knots = c(18, 64)), data = titanic, family = 'binomial')
(pred_plot(bs3_l_mod ) + ggtitle("cubic spline for wine data, 2 knots") +
pred_plot2(bs3_l_log ) + ggtitle("cubic spline for Titanic data, 2 knots"))</code></pre>
<p><img src="figures/6.splines4.png" class="img-fluid" width="200"></p>
<p><strong>Marginal effects:</strong></p>
<pre><code>bs3_l_mod &lt;- lm(pH ~ bs(fixed_acidity, knots = median(fixed_acidity)), data = winequality_red)</code></pre>
<p><img src="figures/6.splines5.png" class="img-fluid" width="200"></p>
</section>
<section id="constraining-parameters-further-natural-splines" class="level3" data-number="8.3.2">
<h3 data-number="8.3.2" class="anchored" data-anchor-id="constraining-parameters-further-natural-splines"><span class="header-section-number">8.3.2</span> Constraining parameters further: natural splines</h3>
<p>Unfortunately, splines can have high variance at the outer range of the predictors—that is, when X takes on either a very small or very large value. Figure 7.4 shows a fit to the Wage data with three knots. We see that the confidence bands in the boundary region appear fairly wild. A natural spline is a regression spline with additional boundary constraints: the function is required to be linear at the boundary (in the region where X is spline smaller than the smallest knot, or larger than the largest knot). This additional constraint means that natural splines generally produce more stable estimates at the boundaries. In Figure 7.4, a natural cubic spline is also displayed as a red line. Note that the corresponding confidence intervals are narrower.</p>
<p><img src="figures/6.natur.png" class="img-fluid" width="300"></p>
<ul>
<li>extrapolates linearly boundary knots</li>
<li>beyond the range of the data, the function goes off linerarly</li>
<li>This adds extra constraints, and allows us to put more internal knots for the same degrees of freedom as a regular cubic spline.</li>
<li>Parameters <span class="math inline">\((d+1) + K-2\)</span> (two constrains in the boundaries) → removing degrees of freedom</li>
</ul>
<p><strong>in R</strong></p>
<p>Using ‘splines’ and ‘ns(x, …)’</p>
<pre><code>ns3_l_mo &lt;- lm(pH ~ ns(fixed_acidity, knots = c(6, 8), data = winequality_red)
ns3_l_log &lt;- glm(Survived ~ ns(`Age`, knots = c(18, 64)), data = titanic, family = 'binomial')</code></pre>
<p><img src="figures/6.natur2.png" class="img-fluid" width="250"></p>
<ul>
<li>we de not have the decrease at the end. Make it more linear, what is good because ends are often wild.</li>
</ul>
<p>→ to use, when the test data set gets out of the range of observations and are kind of outliers. → more simple models, less parameters!</p>
</section>
</section>
<section id="choosing-k-and-the-placements-of-knots" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="choosing-k-and-the-placements-of-knots"><span class="header-section-number">8.4</span> Choosing K and the placements of knots</h2>
<p>Various strategies:</p>
<ul>
<li><p>Given the theoretical framework of the data at hand, there are logical, natural places for the knots</p></li>
<li><p>Given the data, place more knots in places where we feel the function might vary most rapidly, and to place fewer knots where it seems more stable. Very data dependent!</p></li>
<li><p>More common: place knots in a uniform fashion. That is:</p></li>
<li><p>Decide on <span class="math inline">\(K\)</span> (the number of knots) and place them at the quantiles of the observed <span class="math inline">\(X\)</span>. For example, if we choose 1 knot, we can place it at the median of <span class="math inline">\(X\)</span></p></li>
<li><p>Deciding on <span class="math inline">\(K\)</span> : use cross-validation</p></li>
<li><p>in splines is more about making predictions, than to explain and estimate exact parameters, so more parameters do not harm! Add all!</p></li>
</ul>
<section id="smoothing-splines" class="level3" data-number="8.4.1">
<h3 data-number="8.4.1" class="anchored" data-anchor-id="smoothing-splines"><span class="header-section-number">8.4.1</span> Smoothing splines</h3>
<p>Even more advanced method, for fitting splines without having to worry about knots. - Basic idea similar to Ridge regression: - add a roughness penalty: Minimize <span class="math inline">\(MSE + \lambda penalty\)</span> - Penalty is <span class="math inline">\(\int f''(r)^2\)</span>: Sum of change in the curvature</p>
<p><img src="figures/6.smooth2.png" class="img-fluid" width="100"></p>
<p>In fitting a smooth curve to a set of data, what we really want to do is find some function, say g(x), that fits the observed data well: that is, we want RSS/ MSE to be small. However, there is a problem with this approach. If we don’t put any constraints on g(xi), then we can always make RSS zero simply by choosing g such that it interpolates all of the yi. Such a function would woefully overfit the data—it would be far too flexible. What we really want is a function g that makes RSS small, but that is also smooth. How might we ensure that g is smooth? There are a number of ways to do this. A natural approach is to find the function g that minimizes the MSE, where <span class="math inline">\(\lambda\)</span> is the nonnegative tuning parameter.</p>
<ul>
<li>How many knots? One for each <span class="math inline">\(x_i\)</span>, controll smoothness through penalty</li>
<li><span class="math inline">\(f(x)\)</span> ends up being a piecewise cubic polynomial and continuous first and second derivatives</li>
<li>the smaller <span class="math inline">\(\lambda\)</span> the more wiggly (wackelig, sich schlangend) the function, <span class="math inline">\(\lambda\)</span> → <span class="math inline">\(\infty\)</span> <span class="math inline">\(g(x)\)</span> becomes linear</li>
</ul>
<section id="advantages" class="level4" data-number="8.4.1.1">
<h4 data-number="8.4.1.1" class="anchored" data-anchor-id="advantages"><span class="header-section-number">8.4.1.1</span> Advantages</h4>
<ul>
<li>No need to define the number of knots</li>
<li><span class="math inline">\(\lambda\)</span> can be calculated easily due to some math magic without the need of cross-validation (i.e.&nbsp;faster)</li>
<li>Less “effective degrees of freedom” (parameters)#</li>
</ul>
<p><strong>in R</strong></p>
<pre><code># Cross validation to find best lambda
ss_mod1 &lt;- smooth.spline(winequality_red$fixed_acidity, winequality_red$pH, cv = TRUE)
# Effective degrees of freedom
ss_mod1$df
## [1] 10.61691
#Fit linear model
ss_mod &lt;- gam(pH ~ s(fixed_acidity, df = 10.6), data = winequality_red)</code></pre>
<p><img src="figures/6.smooth.png" class="img-fluid" width="300"></p>
</section>
</section>
</section>
<section id="local-regression" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="local-regression"><span class="header-section-number">8.5</span> Local regression</h2>
<ul>
<li>mainly used to predict trends</li>
<li>The idea of local regression can be generalized in many different ways. In a setting with multiple features X1,X2, . . . ,Xp, one very useful generalization involves fitting a multiple linear regression model that is global some variables, but local in another, such as time. Such varying coefficient models are a useful way of adapting a model to the most recently gathered data.</li>
<li>Local regression is a different approach for fitting flexible non-linear functions, which involves computing the fit at a target point x0 using only the nearby training observations.</li>
<li>In this figure the blue line represents the function <span class="math inline">\(f(x)\)</span> from which the data were generated, and the light orange line corresponds to the local regression estimate <span class="math inline">\(\hat{f}(x)\)</span>.</li>
</ul>
<p><img src="figures/6.local2.png" class="img-fluid" width="300"></p>
<p>Note that in Step 3 of Algorithm 7.1, the weights Ki0 will differ for each value of x0. In other words, in order to obtain the local regression fit at a new point, we need to fit a new weighted least squares regression model by minimizing (7.14) for a new set of weights. Local regression is sometimes referred to as a memory-based procedure, because like nearest-neighbors, we need all the training data each time we wish to compute a prediction. In order to perform local regression, there are a number of choices to be made, such as how to define the weighting function K, and whether to fit a linear, constant, or quadratic regression in Step 3. (Equation 7.14 corresponds to a linear regression.) While all of these choices make some difference, the most important choice is the span s, which is the proportion of points used to compute the local regression at x0, as defined in Step 1 above. The span plays a role like that of the tuning parameter λ in smoothing splines: it controls the flexibility of the non-linear fit. The smaller the value of s, the more local and wiggly will be our fit; alternatively, a very large value of s will lead to a global fit to the data using all of the training observations. → crossvalidation to choose s or direct specification.</p>
<p><strong>in R</strong></p>
<p>use the funcion <code>loess</code></p>
<p><img src="figures/6.local.png" class="img-fluid" width="300"></p>
</section>
<section id="generalized-additive-models-gam" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="generalized-additive-models-gam"><span class="header-section-number">8.6</span> Generalized additive models (GAM)</h2>
<p>Generalized additive models (GAMs) provide a general framework for extending a standard linear model by allowing non-linear functions of each of the variables, while maintaining additivity. Just like linear models, GAMs can be applied with both quantitative and qualitative responses.</p>
<p><strong>Use &amp; Pros:</strong></p>
<ul>
<li>When using the above methods on a multiple regression (i.e., more than 1 predictor) problem, we can extend them using GAM (generalized additive models)</li>
<li>Allows for flexible nonlinearities in several variables</li>
<li>Addition of smooth functions</li>
<li>quite easy to use</li>
<li>also possible to mic methods over different predictors within the same model, e.g.&nbsp;a model that is global on some variables, - local in other (e.g.&nbsp;time)</li>
</ul>
<p><strong>Cons:</strong></p>
<p>The main limitation of GAMs is that the model is restricted to be additive. With many variables, important interactions can be missed. However, as with linear regression, we can manually add interaction terms to the GAM model by including additional predictors of the form Xj × Xk. In addition we can add low-dimensional interaction functions of the form fjk(Xj,Xk) into the model; such terms can be fit using two-dimensional smoothers such as local regression, or two-dimensional splines (not covered here)</p>
<p><strong>in R</strong></p>
<pre><code>library(gam)

#Example 1: more than one natural spline
R: lm(wage ∼ ns(year, df = 5) + ns(age, df = 5) + education)

# Example 2: different methods
m(wage ∼ ns(year, df = 5) + lo(age, span = 0.5) + education)</code></pre>
</section>
<section id="in-r" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="in-r"><span class="header-section-number">8.7</span> in R</h2>
<p>In this lab, we will learn about nonlinear extensions to regression using basis functions and how to create, visualise, and interpret them. Parts of it are adapted from the labs in ISLR chapter 7. You can download the student zip including all needed files for lab 6 <a href="https://surfdrive.surf.nl/files/index.php/s/J58fxg4AkOSKTcK">here</a>.</p>
<p>One of the packages we are going to use is <code>splines</code>. For this, you will probably need to <code>install.packages("splines")</code> before running the <code>library()</code> functions, however depending on when you installed <code>R</code>, it may be a base function within your library.</p>
<p>Additionally this lab will use lots of functions from the <code>tidyverse</code> package <code>dplyr</code>. Therefore, if you are struggling with there usage, please review the guidance in the <a href="https://adav-course-2022.netlify.app/4_linregds/basic_dplyr/">dplyr basics tab</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(splines)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Median housing prices in Boston do not have a linear relation with the proportion of low SES households. Today we are going to focus exclusively on <em>prediction</em>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>Boston <span class="sc">%&gt;%</span> </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> lstat, <span class="at">y =</span> medv)) <span class="sc">+</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="beyond-linearity_files/figure-html/houseprice-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>First, we need a way of visualising the predictions. The below function <code>pred_plot()</code> does this for us: the function <code>pred_plot()</code> takes as input an <code>lm</code> object, which outputs the above plot but with a prediction line generated from the model object using the <code>predict()</code> method.</p>
<ol type="1">
<li><strong>Identify what each line of code does within the function <code>pred_plot()</code>. Next, using # annotate what each line does within the function.</strong></li>
</ol>
<p><em>hint</em>: You can use the function <code>print()</code> to output and investigate what lines within the function are doing.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>pred_plot <span class="ot">&lt;-</span> <span class="cf">function</span>(model) { <span class="co">#defines the function, needs model as an argument</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  x_pred <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(Boston<span class="sc">$</span>lstat), <span class="fu">max</span>(Boston<span class="sc">$</span>lstat), <span class="at">length.out =</span> <span class="dv">500</span>) <span class="co"># set the x value for pred from the lowest lstat value to the highest. We now get a vector with 500 values from the lowest lstat to the highest. The numbers are generated randomly, so we have simulated data.</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">lstat =</span> x_pred)) <span class="co">#we predict the numeric outcome for y based on model we have defined and use for the prediction the randomly generated data x_pred</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  Boston <span class="sc">%&gt;%</span> <span class="co">#we set the data that we want to use</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> lstat, <span class="at">y =</span> medv)) <span class="sc">+</span> <span class="co">#we define the asthetics and map them</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">alpha=</span> <span class="fl">0.7</span>, <span class="at">color=</span> <span class="st">"steelblue4"</span>) <span class="sc">+</span> <span class="co">#we want a scatterplot, so we define the associated geom</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">lstat =</span> x_pred, <span class="at">medv =</span> y_pred), <span class="at">size =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">"purple"</span>) <span class="sc">+</span> <span class="co">#we add a line for the predicted y on the predicted x data</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="co"># we define a nice theme</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="2" type="1">
<li><strong>Create a linear regression object called <code>lin_mod</code> which models <code>medv</code> as a function of <code>lstat</code>. Check if the prediction plot works by running <code>pred_plot(lin_mod)</code>. Do you see anything out of the ordinary with the predictions?</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>lin_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat, <span class="at">data=</span> Boston)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pred_plot</span>(lin_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</code></pre>
</div>
<div class="cell-output-display">
<p><img src="beyond-linearity_files/figure-html/predplot lin_mod-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We can see that the predictions do not perform well for the low SES households and the very high SES households. Further, the line seems to be too high in the middle, it seems like it is pushed up because of the many observations with low lstat and high medv.</p>
<p>→ linear regression underfits the data, is too simple to grasp. Too less variance explained</p>
<section id="polynomial-regression-1" class="level3" data-number="8.7.1">
<h3 data-number="8.7.1" class="anchored" data-anchor-id="polynomial-regression-1"><span class="header-section-number">8.7.1</span> Polynomial regression</h3>
<p>The first extension to linear regression is polynomial regression, with basis functions <span class="math inline">\(\beta_{j}(x_{i}^{j})\)</span> (ISLR, p.&nbsp;270).</p>
<ol start="3" type="1">
<li><strong>Create another linear model <code>pn3_mod</code>, where you add the second and third-degree polynomial terms <code>I(lstat^2)</code> and <code>I(lstat^3)</code> to the formula. Create a <code>pred_plot()</code> with this model.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>pn3_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">poly</span>(lstat,<span class="dv">3</span>), <span class="at">data=</span> Boston) <span class="co">#in this case linear combination of the variables lstat and the polynoms</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(pn3_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    (Intercept) poly(lstat, 3)1 poly(lstat, 3)2 poly(lstat, 3)3 
       22.53281      -152.45955        64.22724       -27.05110 </code></pre>
</div>
</div>
<p>or the other way with the wrapper function <code>I()</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>pn3_mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat <span class="sc">+</span> <span class="fu">I</span>(lstat<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(lstat<span class="sc">^</span><span class="dv">3</span>), <span class="at">data=</span> Boston)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(pn3_mod2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> (Intercept)        lstat   I(lstat^2)   I(lstat^3) 
48.649625342 -3.865592779  0.148738477 -0.002003868 </code></pre>
</div>
</div>
<p>The function <code>poly()</code> can automatically generate a matrix which contains columns with polynomial basis function outputs.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>plot_raw <span class="ot">&lt;-</span> <span class="fu">pred_plot</span>(pn3_mod2)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>plot_raw</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="beyond-linearity_files/figure-html/plot-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol start="4" type="1">
<li><strong>Play around with the poly() function. What output does it generate with the arguments <code>degree = 3</code> and <code>raw = TRUE</code>?</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>pn3_mod.t <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">poly</span>(lstat,<span class="dv">3</span>, <span class="at">raw=</span> <span class="cn">TRUE</span>), <span class="at">data=</span> Boston) <span class="co">#in this case linear</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(pn3_mod.t) <span class="co">#in this case we obtain the variables directly, so equal to the selve written function</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                (Intercept) poly(lstat, 3, raw = TRUE)1 
               48.649625342                -3.865592779 
poly(lstat, 3, raw = TRUE)2 poly(lstat, 3, raw = TRUE)3 
                0.148738477                -0.002003868 </code></pre>
</div>
</div>
<p>Play aroung with poly</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">poly</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="at">degree=</span> <span class="dv">3</span>, <span class="at">raw=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     1  2   3
[1,] 1  1   1
[2,] 2  4   8
[3,] 3  9  27
[4,] 4 16  64
[5,] 5 25 125
attr(,"degree")
[1] 1 2 3
attr(,"class")
[1] "poly"   "matrix"</code></pre>
</div>
</div>
<p><code>Poly</code> compute the x, x^2 and x^3 for all numbers from 5.</p>
<ol start="5" type="1">
<li><strong>Use the poly() function directly in the model formula to create a 3rd-degree polynomial regression predicting <code>medv</code> using <code>lstat</code>. Compare the prediction plot to the previous prediction plot you made. What happens if you change the poly() function to <code>raw = FALSE</code>?</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>plot_notraw <span class="ot">&lt;-</span><span class="fu">pred_plot</span>(pn3_mod)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(plot_raw, plot_notraw, <span class="at">ncol=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="beyond-linearity_files/figure-html/p3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Looks the same for me.</p>
</section>
<section id="piecewise-constant-step-function" class="level3" data-number="8.7.2">
<h3 data-number="8.7.2" class="anchored" data-anchor-id="piecewise-constant-step-function"><span class="header-section-number">8.7.2</span> Piecewise constant (Step function)</h3>
<p>Another basis function we can use is a step function. For example, we can split the <code>lstat</code> variable into two groups based on its median and take the average of these groups to predict <code>medv</code>.</p>
<ol start="6" type="1">
<li><strong>Create a model called <code>pw2_mod</code> with one predictor: <code>I(lstat &lt;= median(lstat))</code>. Create a pred_plot with this model. Use the coefficients in <code>coef(pw2_mod)</code> to find out what the predicted value for a low-lstat neighbourhood is.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>pn2_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">I</span>(lstat <span class="sc">&lt;=</span> <span class="fu">median</span> (lstat)), <span class="at">data=</span> Boston)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pred_plot</span>(pn2_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="beyond-linearity_files/figure-html/pw2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(pn2_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  (Intercept) I(lstat &lt;= median(lstat))TRUE 
                     16.67747                      11.71067 </code></pre>
</div>
</div>
<p>The predicted value for a low-stat neighborhood is .</p>
<ol start="7" type="1">
<li><strong>Use the <code>cut()</code> function in the formula to generate a piecewise regression model called <code>pw5_mod</code> that contains 5 equally spaced sections. Again, plot the result using <code>pred_plot</code>.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>pw5_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">cut</span>(lstat, <span class="at">breaks =</span> <span class="dv">5</span>), <span class="at">data=</span> Boston)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pred_plot</span>(pw5_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="beyond-linearity_files/figure-html/pw5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Note that the sections generated by <code>cut()</code> are equally spaced in terms of <code>lstat</code>, but they do not have equal amounts of data. In fact, the last section has only 9 data points to work with:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">cut</span>(Boston<span class="sc">$</span>lstat, <span class="dv">5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
(1.69,8.98] (8.98,16.2] (16.2,23.5] (23.5,30.7]   (30.7,38] 
        183         183          94          37           9 </code></pre>
</div>
</div>
<ol start="8" type="1">
<li><strong>Optional: Create a piecewise regression model <code>pwq_mod</code> where the sections are not equally spaced, but have equal amounts of training data. Hint: use the <code>quantile()</code> function.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>breaks <span class="ot">&lt;-</span> <span class="fu">quantile</span>(Boston<span class="sc">$</span>lstat, <span class="at">probs=</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="dv">1</span>))</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>breaks <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="cn">Inf</span>, breaks, <span class="cn">Inf</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>breaks</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        20%   40%   60%   80%  100%       
 -Inf  6.29  9.53 13.33 18.06 37.97   Inf </code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>pwq_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span>  <span class="fu">cut</span>(lstat, breaks), <span class="at">data=</span> Boston)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pred_plot</span>(pwq_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="beyond-linearity_files/figure-html/pwq_mod-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(pwq_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  (Intercept) cut(lstat, breaks)(6.29,9.53] 
                    34.089216                     -8.324859 
cut(lstat, breaks)(9.53,13.3] cut(lstat, breaks)(13.3,18.1] 
                   -12.771394                    -16.066443 
  cut(lstat, breaks)(18.1,38] 
                   -20.733770 </code></pre>
</div>
</div>
<p>How to interpret?</p>
<p>For the area where the amount of people having a low status is 20 % the estimate is 34.089. For the lowest 40 % it is 34.089 + (-8.32), and for 34.089 + (- 12.77) and so on.</p>
</section>
<section id="splines-1" class="level3" data-number="8.7.3">
<h3 data-number="8.7.3" class="anchored" data-anchor-id="splines-1"><span class="header-section-number">8.7.3</span> Splines</h3>
<p>Using splines, we can combine polyniomials with step functions (as is done in piecewise polynomical regression, see ISLR and the lecture) AND take out the discontinuities.</p>
<p>The <code>bs()</code> function from the <code>splines</code> package does all the work for us.</p>
<ol start="9" type="1">
<li><strong>Create a cubic spline model <code>bs1_mod</code> with a knot at the median using the <code>bs()</code> function.</strong></li>
</ol>
<p><em>hint</em>: If you are not sure how to use the function <code>bs()</code>, check out the first example at the bottom of the help file by using <code>?bs</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>?bs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>starting httpd help server ... done</code></pre>
</div>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>bs1_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">bs</span>(lstat, <span class="at">knots=</span><span class="fu">median</span> (lstat)), <span class="at">data=</span>Boston)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="10" type="1">
<li><strong>Create a prediction plot from the <code>bs1_mod</code> object using the <code>plot_pred()</code> function.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>bs1 <span class="ot">&lt;-</span> <span class="fu">pred_plot</span>(bs1_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that this line fits very well, but at the right end of the plot, the curve slopes up. Theoretically, this is unexpected – always pay attention to which predictions you are making and whether that behaviour is in line with your expectations.</p>
<p>The last extension we will look at is the natural spline. This works in the same way as the cubic spline, with the additional constraint that the function is required to be linear at the boundaries. The <code>ns()</code> function from the <code>splines</code> package is for generating the basis representation for a natural spline.</p>
<ol start="11" type="1">
<li><strong>Create a natural cubic spline model (<code>ns3_mod</code>) with 3 degrees of freedom using the <code>ns()</code> function. Plot it, and compare it to the <code>bs1_mod</code>.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>?ns</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>ns3_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">ns</span>(lstat, <span class="at">knots =</span> <span class="fu">median</span> (lstat)), <span class="at">data=</span>Boston)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>ns1 <span class="ot">&lt;-</span> <span class="fu">pred_plot</span>(ns3_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(bs1, ns1, <span class="at">ncol=</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="beyond-linearity_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol start="12" type="1">
<li><strong>Plot <code>lin_mod</code>, <code>pn3_mod</code>, <code>pw5_mod</code>, <code>bs1_mod</code>, and <code>ns3_mod</code> and give them nice titles by adding <code>+ ggtitle("My title")</code> to the plot. You may use the function <code>plot_grid()</code> from the package <code>cowplot</code> to put your plots in a grid.</strong></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("cowplot")</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cowplot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'cowplot'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:lubridate':

    stamp</code></pre>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>lin_plot <span class="ot">&lt;-</span> <span class="fu">pred_plot</span>(lin_mod)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>lin_plot <span class="ot">&lt;-</span> lin_plot <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"Linear Model"</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>lin_plot</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="beyond-linearity_files/figure-html/predplots-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>pn3_plot <span class="ot">&lt;-</span> <span class="fu">pred_plot</span>(pn3_mod) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"third-degree polynomial"</span>)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>pw5_plot <span class="ot">&lt;-</span> <span class="fu">pred_plot</span>(pw5_mod) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"piecewise regression"</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">title =</span> <span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">11</span>))</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>bs1 <span class="ot">&lt;-</span> bs1 <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"splines"</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>ns1 <span class="ot">&lt;-</span> ns1 <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"natural splines"</span>)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>?plot_grid</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_grid</span>(lin_plot,pn3_plot, pw5_plot,bs1, ns1, <span class="at">nrow=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="beyond-linearity_files/figure-html/predplots-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>``` ## Conclusions</p>
<ul>
<li>If we are interested in accurate predictions: Splines are preferred over polynomial</li>
<li>They are more flexible than polynomial and local (variance is often lower)</li>
<li>But it comes at a cost (interpretability)</li>
<li>Cubic splines are often all you need</li>
<li>All the methods we have seen so far are additive</li>
</ul>
<p><img src="figures/6.conclusions.png" class="img-fluid" width="490"></p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./classification.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">classification</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./tree-based.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Tree-based Methods</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>